Compiled from "EsInputFormat.java"
public class org.elasticsearch.hadoop.mr.EsInputFormat<K, V> extends org.apache.hadoop.mapreduce.InputFormat<K, V> implements org.apache.hadoop.mapred.InputFormat<K, V> {
  private static org.apache.commons.logging.Log log;

  public org.elasticsearch.hadoop.mr.EsInputFormat();
    Code:
       0: aload_0
       1: invokespecial #7                  // Method org/apache/hadoop/mapreduce/InputFormat."<init>":()V
       4: return

  public java.util.List<org.apache.hadoop.mapreduce.InputSplit> getSplits(org.apache.hadoop.mapreduce.JobContext) throws java.io.IOException;
    Code:
       0: aload_1
       1: invokestatic  #13                 // Method org/elasticsearch/hadoop/mr/compat/CompatHandler.jobContext:(Lorg/apache/hadoop/mapreduce/JobContext;)Lorg/elasticsearch/hadoop/mr/compat/JobContext;
       4: invokeinterface #19,  1           // InterfaceMethod org/elasticsearch/hadoop/mr/compat/JobContext.getConfiguration:()Lorg/apache/hadoop/conf/Configuration;
       9: invokestatic  #25                 // Method org/elasticsearch/hadoop/mr/HadoopCfgUtils.asJobConf:(Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/mapred/JobConf;
      12: astore_2
      13: aload_0
      14: aload_2
      15: aload_2
      16: invokevirtual #31                 // Method org/apache/hadoop/mapred/JobConf.getNumMapTasks:()I
      19: invokevirtual #37                 // Method getSplits:(Lorg/apache/hadoop/mapred/JobConf;I)[Lorg/apache/hadoop/mapred/InputSplit;
      22: checkcast     #41                 // class "[Lorg/apache/hadoop/mapreduce/InputSplit;"
      25: invokestatic  #43                 // Method java/util/Arrays.asList:([Ljava/lang/Object;)Ljava/util/List;
      28: areturn

  public org.elasticsearch.hadoop.mr.EsInputFormat$EsInputRecordReader<K, V> createRecordReader(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext);
    Code:
       0: aload_0
       1: aload_2
       2: invokestatic  #49                 // Method org/elasticsearch/hadoop/mr/compat/CompatHandler.taskAttemptContext:(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/elasticsearch/hadoop/mr/compat/TaskAttemptContext;
       5: invokeinterface #53,  1           // InterfaceMethod org/elasticsearch/hadoop/mr/compat/TaskAttemptContext.getConfiguration:()Lorg/apache/hadoop/conf/Configuration;
      10: invokevirtual #56                 // Method isOutputAsJson:(Lorg/apache/hadoop/conf/Configuration;)Z
      13: ifeq          26
      16: new           #60                 // class org/elasticsearch/hadoop/mr/EsInputFormat$JsonWritableEsInputRecordReader
      19: dup
      20: invokespecial #62                 // Method org/elasticsearch/hadoop/mr/EsInputFormat$JsonWritableEsInputRecordReader."<init>":()V
      23: goto          33
      26: new           #63                 // class org/elasticsearch/hadoop/mr/EsInputFormat$WritableEsInputRecordReader
      29: dup
      30: invokespecial #65                 // Method org/elasticsearch/hadoop/mr/EsInputFormat$WritableEsInputRecordReader."<init>":()V
      33: areturn

  public org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf, int) throws java.io.IOException;
    Code:
       0: aload_1
       1: invokestatic  #66                 // Method org/elasticsearch/hadoop/cfg/HadoopSettingsManager.loadFrom:(Ljava/lang/Object;)Lorg/elasticsearch/hadoop/cfg/Settings;
       4: astore_3
       5: aload_3
       6: getstatic     #1                  // Field log:Lorg/apache/commons/logging/Log;
       9: invokestatic  #72                 // Method org/elasticsearch/hadoop/rest/RestService.findPartitions:(Lorg/elasticsearch/hadoop/cfg/Settings;Lorg/apache/commons/logging/Log;)Ljava/util/List;
      12: astore        4
      14: aload         4
      16: invokeinterface #78,  1           // InterfaceMethod java/util/Collection.size:()I
      21: anewarray     #83                 // class org/elasticsearch/hadoop/mr/EsInputFormat$EsInputSplit
      24: astore        5
      26: iconst_0
      27: istore        6
      29: aload         4
      31: invokeinterface #85,  1           // InterfaceMethod java/util/Collection.iterator:()Ljava/util/Iterator;
      36: astore        7
      38: aload         7
      40: invokeinterface #89,  1           // InterfaceMethod java/util/Iterator.hasNext:()Z
      45: ifeq          80
      48: aload         7
      50: invokeinterface #95,  1           // InterfaceMethod java/util/Iterator.next:()Ljava/lang/Object;
      55: checkcast     #99                 // class org/elasticsearch/hadoop/rest/PartitionDefinition
      58: astore        8
      60: aload         5
      62: iload         6
      64: iinc          6, 1
      67: new           #83                 // class org/elasticsearch/hadoop/mr/EsInputFormat$EsInputSplit
      70: dup
      71: aload         8
      73: invokespecial #101                // Method org/elasticsearch/hadoop/mr/EsInputFormat$EsInputSplit."<init>":(Lorg/elasticsearch/hadoop/rest/PartitionDefinition;)V
      76: aastore
      77: goto          38
      80: getstatic     #1                  // Field log:Lorg/apache/commons/logging/Log;
      83: ldc           #104                // String Created [%d] splits
      85: iconst_1
      86: anewarray     #106                // class java/lang/Object
      89: dup
      90: iconst_0
      91: aload         5
      93: arraylength
      94: invokestatic  #108                // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;
      97: aastore
      98: invokestatic  #114                // Method java/lang/String.format:(Ljava/lang/String;[Ljava/lang/Object;)Ljava/lang/String;
     101: invokeinterface #120,  2          // InterfaceMethod org/apache/commons/logging/Log.info:(Ljava/lang/Object;)V
     106: aload         5
     108: areturn

  public org.elasticsearch.hadoop.mr.EsInputFormat$EsInputRecordReader<K, V> getRecordReader(org.apache.hadoop.mapred.InputSplit, org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.Reporter);
    Code:
       0: aload_0
       1: aload_2
       2: invokevirtual #56                 // Method isOutputAsJson:(Lorg/apache/hadoop/conf/Configuration;)Z
       5: ifeq          21
       8: new           #60                 // class org/elasticsearch/hadoop/mr/EsInputFormat$JsonWritableEsInputRecordReader
      11: dup
      12: aload_1
      13: aload_2
      14: aload_3
      15: invokespecial #126                // Method org/elasticsearch/hadoop/mr/EsInputFormat$JsonWritableEsInputRecordReader."<init>":(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/mapred/Reporter;)V
      18: goto          31
      21: new           #63                 // class org/elasticsearch/hadoop/mr/EsInputFormat$WritableEsInputRecordReader
      24: dup
      25: aload_1
      26: aload_2
      27: aload_3
      28: invokespecial #129                // Method org/elasticsearch/hadoop/mr/EsInputFormat$WritableEsInputRecordReader."<init>":(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/mapred/Reporter;)V
      31: areturn

  protected boolean isOutputAsJson(org.apache.hadoop.conf.Configuration);
    Code:
       0: new           #130                // class org/elasticsearch/hadoop/cfg/HadoopSettings
       3: dup
       4: aload_1
       5: invokespecial #132                // Method org/elasticsearch/hadoop/cfg/HadoopSettings."<init>":(Lorg/apache/hadoop/conf/Configuration;)V
       8: invokevirtual #135                // Method org/elasticsearch/hadoop/cfg/HadoopSettings.getOutputAsJson:()Z
      11: ireturn

  public org.apache.hadoop.mapreduce.RecordReader createRecordReader(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext) throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_0
       1: aload_1
       2: aload_2
       3: invokevirtual #138                // Method createRecordReader:(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/elasticsearch/hadoop/mr/EsInputFormat$EsInputRecordReader;
       6: areturn

  public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit, org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.Reporter) throws java.io.IOException;
    Code:
       0: aload_0
       1: aload_1
       2: aload_2
       3: aload_3
       4: invokevirtual #142                // Method getRecordReader:(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/elasticsearch/hadoop/mr/EsInputFormat$EsInputRecordReader;
       7: areturn

  static org.apache.commons.logging.Log access$000();
    Code:
       0: getstatic     #1                  // Field log:Lorg/apache/commons/logging/Log;
       3: areturn

  static {};
    Code:
       0: ldc           #2                  // class org/elasticsearch/hadoop/mr/EsInputFormat
       2: invokestatic  #146                // Method org/apache/commons/logging/LogFactory.getLog:(Ljava/lang/Class;)Lorg/apache/commons/logging/Log;
       5: putstatic     #1                  // Field log:Lorg/apache/commons/logging/Log;
       8: return
}
