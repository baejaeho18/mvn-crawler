Compiled from "ClientDatanodeProtocolProtos.java"
final class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$BlockingStub implements org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$BlockingInterface {
  private final com.google.protobuf.BlockingRpcChannel channel;

  private org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$BlockingStub(com.google.protobuf.BlockingRpcChannel);
    Code:
       0: aload_0
       1: invokespecial #2                  // Method java/lang/Object."<init>":()V
       4: aload_0
       5: aload_1
       6: putfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       9: return

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto getReplicaVisibleLength(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_0
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #8                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #10                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto refreshNamenodes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_1
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #11                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #12                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto deleteBlockPool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_2
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #13                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #14                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto getBlockLocalPathInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_3
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #15                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #16                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto shutdownDatanode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_4
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #17                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #18                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto evictWriters(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_5
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #19                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #20                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto getDatanodeInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        6
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #21                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #22                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto getVolumeReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        7
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #23                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #24                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto getReconfigurationStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        8
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #25                 // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #26                 // class org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto startReconfiguration(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        9
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #27                 // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #28                 // class org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto listReconfigurableProperties(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        10
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #29                 // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #30                 // class org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto triggerBlockReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        11
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #31                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #32                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto getBalancerBandwidth(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        12
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #33                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #34                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto submitDiskBalancerPlan(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        13
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #35                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #36                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto cancelDiskBalancerPlan(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        14
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #37                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #38                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto queryDiskBalancerPlan(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        15
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #39                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #40                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto getDiskBalancerSetting(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        16
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #41                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #42                 // class org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto
      33: areturn

  org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$BlockingStub(com.google.protobuf.BlockingRpcChannel, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$1);
    Code:
       0: aload_0
       1: aload_1
       2: invokespecial #1                  // Method "<init>":(Lcom/google/protobuf/BlockingRpcChannel;)V
       5: return
}
