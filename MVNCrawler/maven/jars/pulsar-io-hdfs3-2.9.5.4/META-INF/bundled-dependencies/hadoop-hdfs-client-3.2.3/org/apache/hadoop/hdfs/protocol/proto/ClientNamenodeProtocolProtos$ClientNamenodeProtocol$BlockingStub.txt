Compiled from "ClientNamenodeProtocolProtos.java"
final class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$BlockingStub implements org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$BlockingInterface {
  private final com.google.protobuf.BlockingRpcChannel channel;

  private org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$BlockingStub(com.google.protobuf.BlockingRpcChannel);
    Code:
       0: aload_0
       1: invokespecial #2                  // Method java/lang/Object."<init>":()V
       4: aload_0
       5: aload_1
       6: putfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       9: return

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto getBlockLocations(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_0
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #8                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #10                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto getServerDefaults(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_1
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #11                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #12                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto create(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_2
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #13                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #14                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto append(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_3
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #15                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AppendResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AppendResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #16                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AppendResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto setReplication(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_4
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #17                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetReplicationResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetReplicationResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #18                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetReplicationResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto setStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: iconst_5
      11: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      16: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      19: aload_1
      20: aload_2
      21: invokestatic  #19                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto;
      24: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      29: checkcast     #20                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto
      32: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto unsetStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        6
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #21                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #22                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto getStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        7
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #23                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #24                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto getStoragePolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        8
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #25                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #26                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto setPermission(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        9
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #27                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetPermissionResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetPermissionResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #28                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetPermissionResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto setOwner(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        10
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #29                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetOwnerResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetOwnerResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #30                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetOwnerResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto abandonBlock(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        11
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #31                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AbandonBlockResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AbandonBlockResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #32                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AbandonBlockResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto addBlock(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        12
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #33                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddBlockResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddBlockResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #34                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddBlockResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto getAdditionalDatanode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        13
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #35                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #36                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto complete(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        14
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #37                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CompleteResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CompleteResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #38                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CompleteResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto reportBadBlocks(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        15
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #39                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #40                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto concat(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        16
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #41                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ConcatResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ConcatResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #42                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ConcatResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto truncate(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        17
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #43                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$TruncateResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$TruncateResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #44                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$TruncateResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto rename(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        18
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #45                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #46                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto rename2(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        19
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #47                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$Rename2ResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$Rename2ResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #48                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$Rename2ResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto delete(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        20
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #49                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #50                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto mkdirs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        21
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #51                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MkdirsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MkdirsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #52                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MkdirsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto getListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        22
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #53                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetListingResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetListingResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #54                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetListingResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto renewLease(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        23
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #55                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenewLeaseResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenewLeaseResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #56                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenewLeaseResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto recoverLease(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        24
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #57                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RecoverLeaseResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RecoverLeaseResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #58                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RecoverLeaseResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto getFsStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        25
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #59                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsStatsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsStatsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #60                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsStatsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto getFsReplicatedBlockStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        26
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #61                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #62                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto getFsECBlockGroupStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        27
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #63                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #64                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto getDatanodeReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        28
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #65                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #66                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto getDatanodeStorageReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        29
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #67                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #68                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto getPreferredBlockSize(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        30
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #69                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #70                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto setSafeMode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        31
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #71                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetSafeModeResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetSafeModeResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #72                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetSafeModeResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto saveNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        32
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #73                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SaveNamespaceResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SaveNamespaceResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #74                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SaveNamespaceResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto rollEdits(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        33
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #75                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollEditsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollEditsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #76                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollEditsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto restoreFailedStorage(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        34
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #77                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #78                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto refreshNodes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        35
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #79                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RefreshNodesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RefreshNodesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #80                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RefreshNodesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto finalizeUpgrade(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        36
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #81                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #82                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto upgradeStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        37
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #83                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpgradeStatusResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpgradeStatusResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #84                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpgradeStatusResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto rollingUpgrade(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        38
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #85                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollingUpgradeResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollingUpgradeResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #86                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollingUpgradeResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto listCorruptFileBlocks(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        39
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #87                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #88                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto metaSave(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        40
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #89                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MetaSaveResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MetaSaveResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #90                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MetaSaveResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto getFileInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        41
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #91                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileInfoResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileInfoResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #92                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileInfoResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto getLocatedFileInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        42
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #93                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #94                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto addCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        43
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #95                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #96                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto modifyCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        44
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #97                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #98                 // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto removeCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        45
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #99                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #100                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto listCacheDirectives(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        46
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #101                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #102                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto addCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        47
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #103                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCachePoolResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCachePoolResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #104                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCachePoolResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto modifyCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        48
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #105                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #106                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto removeCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        49
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #107                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #108                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto listCachePools(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        50
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #109                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCachePoolsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCachePoolsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #110                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCachePoolsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto getFileLinkInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        51
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #111                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #112                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto getContentSummary(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        52
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #113                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetContentSummaryResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetContentSummaryResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #114                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetContentSummaryResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto setQuota(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        53
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #115                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetQuotaResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetQuotaResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #116                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetQuotaResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto fsync(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        54
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #117                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FsyncResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FsyncResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #118                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FsyncResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto setTimes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        55
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #119                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetTimesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetTimesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #120                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetTimesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto createSymlink(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        56
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #121                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSymlinkResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSymlinkResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #122                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSymlinkResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto getLinkTarget(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        57
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #123                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLinkTargetResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLinkTargetResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #124                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLinkTargetResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto updateBlockForPipeline(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        58
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #125                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #126                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto updatePipeline(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        59
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #127                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdatePipelineResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdatePipelineResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #128                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdatePipelineResponseProto
      33: areturn

  public org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenResponseProto getDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        60
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #129                // Method org/apache/hadoop/security/proto/SecurityProtos$GetDelegationTokenResponseProto.getDefaultInstance:()Lorg/apache/hadoop/security/proto/SecurityProtos$GetDelegationTokenResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #130                // class org/apache/hadoop/security/proto/SecurityProtos$GetDelegationTokenResponseProto
      33: areturn

  public org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenResponseProto renewDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        61
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #131                // Method org/apache/hadoop/security/proto/SecurityProtos$RenewDelegationTokenResponseProto.getDefaultInstance:()Lorg/apache/hadoop/security/proto/SecurityProtos$RenewDelegationTokenResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #132                // class org/apache/hadoop/security/proto/SecurityProtos$RenewDelegationTokenResponseProto
      33: areturn

  public org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenResponseProto cancelDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        62
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #133                // Method org/apache/hadoop/security/proto/SecurityProtos$CancelDelegationTokenResponseProto.getDefaultInstance:()Lorg/apache/hadoop/security/proto/SecurityProtos$CancelDelegationTokenResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #134                // class org/apache/hadoop/security/proto/SecurityProtos$CancelDelegationTokenResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto setBalancerBandwidth(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        63
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #135                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #136                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto getDataEncryptionKey(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        64
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #137                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #138                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto createSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        65
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #139                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSnapshotResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSnapshotResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #140                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSnapshotResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto renameSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        66
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #141                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameSnapshotResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameSnapshotResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #142                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameSnapshotResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto allowSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        67
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #143                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AllowSnapshotResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AllowSnapshotResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #144                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AllowSnapshotResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto disallowSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        68
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #145                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #146                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto getSnapshottableDirListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        69
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #147                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #148                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto deleteSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        70
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #149                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #150                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto getSnapshotDiffReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        71
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #151                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #152                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto getSnapshotDiffReportListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        72
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #153                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #154                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto isFileClosed(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        73
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #155                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$IsFileClosedResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$IsFileClosedResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #156                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$IsFileClosedResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto modifyAclEntries(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        74
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #157                // Method org/apache/hadoop/hdfs/protocol/proto/AclProtos$ModifyAclEntriesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$ModifyAclEntriesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #158                // class org/apache/hadoop/hdfs/protocol/proto/AclProtos$ModifyAclEntriesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto removeAclEntries(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        75
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #159                // Method org/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclEntriesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclEntriesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #160                // class org/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclEntriesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto removeDefaultAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        76
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #161                // Method org/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveDefaultAclResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveDefaultAclResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #162                // class org/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveDefaultAclResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto removeAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        77
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #163                // Method org/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #164                // class org/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto setAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        78
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #165                // Method org/apache/hadoop/hdfs/protocol/proto/AclProtos$SetAclResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$SetAclResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #166                // class org/apache/hadoop/hdfs/protocol/proto/AclProtos$SetAclResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto getAclStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        79
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #167                // Method org/apache/hadoop/hdfs/protocol/proto/AclProtos$GetAclStatusResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$GetAclStatusResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #168                // class org/apache/hadoop/hdfs/protocol/proto/AclProtos$GetAclStatusResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto setXAttr(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        80
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #169                // Method org/apache/hadoop/hdfs/protocol/proto/XAttrProtos$SetXAttrResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$SetXAttrResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #170                // class org/apache/hadoop/hdfs/protocol/proto/XAttrProtos$SetXAttrResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto getXAttrs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        81
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #171                // Method org/apache/hadoop/hdfs/protocol/proto/XAttrProtos$GetXAttrsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$GetXAttrsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #172                // class org/apache/hadoop/hdfs/protocol/proto/XAttrProtos$GetXAttrsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto listXAttrs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        82
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #173                // Method org/apache/hadoop/hdfs/protocol/proto/XAttrProtos$ListXAttrsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$ListXAttrsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #174                // class org/apache/hadoop/hdfs/protocol/proto/XAttrProtos$ListXAttrsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto removeXAttr(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        83
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #175                // Method org/apache/hadoop/hdfs/protocol/proto/XAttrProtos$RemoveXAttrResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$RemoveXAttrResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #176                // class org/apache/hadoop/hdfs/protocol/proto/XAttrProtos$RemoveXAttrResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto checkAccess(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        84
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #177                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CheckAccessResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CheckAccessResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #178                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CheckAccessResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto createEncryptionZone(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        85
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #179                // Method org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$CreateEncryptionZoneResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$CreateEncryptionZoneResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #180                // class org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$CreateEncryptionZoneResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto listEncryptionZones(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        86
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #181                // Method org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListEncryptionZonesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListEncryptionZonesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #182                // class org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListEncryptionZonesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto reencryptEncryptionZone(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        87
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #183                // Method org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #184                // class org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto listReencryptionStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        88
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #185                // Method org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListReencryptionStatusResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListReencryptionStatusResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #186                // class org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListReencryptionStatusResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto getEZForPath(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        89
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #187                // Method org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$GetEZForPathResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$GetEZForPathResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #188                // class org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$GetEZForPathResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto setErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        90
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #189                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$SetErasureCodingPolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$SetErasureCodingPolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #190                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$SetErasureCodingPolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto unsetErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        91
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #191                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #192                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetECTopologyResultForPoliciesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        92
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #193                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetECTopologyResultForPoliciesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetECTopologyResultForPoliciesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #194                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetECTopologyResultForPoliciesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto getCurrentEditLogTxid(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        93
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #195                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #196                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto getEditsFromTxid(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        94
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #197                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #198                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto getErasureCodingPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        95
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #199                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPoliciesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPoliciesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #200                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPoliciesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto addErasureCodingPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        96
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #201                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$AddErasureCodingPoliciesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$AddErasureCodingPoliciesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #202                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$AddErasureCodingPoliciesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto removeErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        97
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #203                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #204                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto enableErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        98
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #205                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$EnableErasureCodingPolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$EnableErasureCodingPolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #206                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$EnableErasureCodingPolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto disableErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        99
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #207                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$DisableErasureCodingPolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$DisableErasureCodingPolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #208                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$DisableErasureCodingPolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto getErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        100
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #209                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #210                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto getErasureCodingCodecs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        101
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #211                // Method org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingCodecsResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingCodecsResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #212                // class org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingCodecsResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto getQuotaUsage(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        102
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #213                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #214                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto listOpenFiles(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        103
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #215                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListOpenFilesResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListOpenFilesResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #216                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListOpenFilesResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MsyncResponseProto msync(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MsyncRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        104
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #217                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MsyncResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MsyncResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #218                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MsyncResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyResponseProto satisfyStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        105
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #219                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SatisfyStoragePolicyResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SatisfyStoragePolicyResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #220                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SatisfyStoragePolicyResponseProto
      33: areturn

  public org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$HAServiceStateResponseProto getHAServiceState(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$HAServiceStateRequestProto) throws com.google.protobuf.ServiceException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field channel:Lcom/google/protobuf/BlockingRpcChannel;
       4: invokestatic  #4                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor:()Lcom/google/protobuf/Descriptors$ServiceDescriptor;
       7: invokevirtual #5                  // Method com/google/protobuf/Descriptors$ServiceDescriptor.getMethods:()Ljava/util/List;
      10: bipush        106
      12: invokeinterface #6,  2            // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;
      17: checkcast     #7                  // class com/google/protobuf/Descriptors$MethodDescriptor
      20: aload_1
      21: aload_2
      22: invokestatic  #221                // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$HAServiceStateResponseProto.getDefaultInstance:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$HAServiceStateResponseProto;
      25: invokeinterface #9,  5            // InterfaceMethod com/google/protobuf/BlockingRpcChannel.callBlockingMethod:(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;
      30: checkcast     #222                // class org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$HAServiceStateResponseProto
      33: areturn

  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$BlockingStub(com.google.protobuf.BlockingRpcChannel, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$1);
    Code:
       0: aload_0
       1: aload_1
       2: invokespecial #1                  // Method "<init>":(Lcom/google/protobuf/BlockingRpcChannel;)V
       5: return
}
