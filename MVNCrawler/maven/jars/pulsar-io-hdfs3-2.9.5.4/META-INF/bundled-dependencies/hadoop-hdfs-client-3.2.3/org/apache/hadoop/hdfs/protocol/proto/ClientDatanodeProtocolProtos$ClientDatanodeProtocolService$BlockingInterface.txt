Compiled from "ClientDatanodeProtocolProtos.java"
public interface org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$BlockingInterface {
  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto getReplicaVisibleLength(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto refreshNamenodes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto deleteBlockPool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto getBlockLocalPathInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto shutdownDatanode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto evictWriters(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto getDatanodeInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto getVolumeReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto getReconfigurationStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto startReconfiguration(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto listReconfigurableProperties(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto triggerBlockReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto getBalancerBandwidth(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto submitDiskBalancerPlan(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto cancelDiskBalancerPlan(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto queryDiskBalancerPlan(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto getDiskBalancerSetting(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto) throws com.google.protobuf.ServiceException;
}
