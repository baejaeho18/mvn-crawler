Compiled from "ClientNamenodeProtocolProtos.java"
final class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$1 extends org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol {
  final org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface val$impl;

  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$1(org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface);
    Code:
       0: aload_0
       1: aload_1
       2: putfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       5: aload_0
       6: invokespecial #2                  // Method org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol."<init>":()V
       9: return

  public void getBlockLocations(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #3,  4            // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getBlockLocations:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getServerDefaults(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #4,  4            // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getServerDefaults:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void create(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #5,  4            // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.create:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void append(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #6,  4            // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.append:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AppendRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setReplication(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #7,  4            // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setReplication:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetReplicationRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #8,  4            // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setStoragePolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void unsetStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #9,  4            // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.unsetStoragePolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #10,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getStoragePolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getStoragePolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #11,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getStoragePolicies:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setPermission(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #12,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setPermission:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetPermissionRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setOwner(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #13,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setOwner:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetOwnerRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void abandonBlock(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #14,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.abandonBlock:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AbandonBlockRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void addBlock(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #15,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.addBlock:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddBlockRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getAdditionalDatanode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #16,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getAdditionalDatanode:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void complete(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #17,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.complete:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CompleteRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void reportBadBlocks(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #18,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.reportBadBlocks:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void concat(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #19,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.concat:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ConcatRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void truncate(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #20,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.truncate:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$TruncateRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void rename(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #21,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.rename:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void rename2(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #22,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.rename2:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$Rename2RequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void delete(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #23,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.delete:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void mkdirs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #24,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.mkdirs:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MkdirsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #25,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getListing:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetListingRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void renewLease(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #26,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.renewLease:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenewLeaseRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void recoverLease(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #27,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.recoverLease:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RecoverLeaseRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getFsStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #28,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getFsStats:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsStatusRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getFsReplicatedBlockStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #29,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getFsReplicatedBlockStats:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getFsECBlockGroupStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #30,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getFsECBlockGroupStats:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getDatanodeReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #31,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getDatanodeReport:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getDatanodeStorageReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #32,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getDatanodeStorageReport:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getPreferredBlockSize(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #33,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getPreferredBlockSize:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setSafeMode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #34,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setSafeMode:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetSafeModeRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void saveNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #35,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.saveNamespace:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SaveNamespaceRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void rollEdits(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #36,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.rollEdits:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollEditsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void restoreFailedStorage(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #37,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.restoreFailedStorage:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void refreshNodes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #38,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.refreshNodes:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RefreshNodesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void finalizeUpgrade(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #39,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.finalizeUpgrade:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void upgradeStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #40,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.upgradeStatus:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpgradeStatusRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void rollingUpgrade(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #41,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.rollingUpgrade:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollingUpgradeRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void listCorruptFileBlocks(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #42,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.listCorruptFileBlocks:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void metaSave(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #43,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.metaSave:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MetaSaveRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getFileInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #44,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getFileInfo:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileInfoRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getLocatedFileInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #45,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getLocatedFileInfo:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void addCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #46,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.addCacheDirective:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void modifyCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #47,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.modifyCacheDirective:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void removeCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #48,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.removeCacheDirective:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void listCacheDirectives(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #49,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.listCacheDirectives:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void addCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #50,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.addCachePool:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCachePoolRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void modifyCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #51,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.modifyCachePool:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void removeCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #52,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.removeCachePool:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void listCachePools(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #53,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.listCachePools:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCachePoolsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getFileLinkInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #54,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getFileLinkInfo:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getContentSummary(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #55,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getContentSummary:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetContentSummaryRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setQuota(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #56,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setQuota:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetQuotaRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void fsync(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #57,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.fsync:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FsyncRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setTimes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #58,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setTimes:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetTimesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void createSymlink(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #59,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.createSymlink:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSymlinkRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getLinkTarget(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #60,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getLinkTarget:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLinkTargetRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void updateBlockForPipeline(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #61,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.updateBlockForPipeline:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void updatePipeline(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #62,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.updatePipeline:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdatePipelineRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #63,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getDelegationToken:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/security/proto/SecurityProtos$GetDelegationTokenRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void renewDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #64,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.renewDelegationToken:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/security/proto/SecurityProtos$RenewDelegationTokenRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void cancelDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #65,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.cancelDelegationToken:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/security/proto/SecurityProtos$CancelDelegationTokenRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setBalancerBandwidth(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #66,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setBalancerBandwidth:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getDataEncryptionKey(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #67,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getDataEncryptionKey:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void createSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #68,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.createSnapshot:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSnapshotRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void renameSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #69,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.renameSnapshot:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameSnapshotRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void allowSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #70,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.allowSnapshot:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AllowSnapshotRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void disallowSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #71,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.disallowSnapshot:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getSnapshottableDirListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #72,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getSnapshottableDirListing:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void deleteSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #73,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.deleteSnapshot:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getSnapshotDiffReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #74,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getSnapshotDiffReport:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getSnapshotDiffReportListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #75,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getSnapshotDiffReportListing:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void isFileClosed(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #76,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.isFileClosed:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$IsFileClosedRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void modifyAclEntries(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #77,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.modifyAclEntries:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$ModifyAclEntriesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void removeAclEntries(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #78,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.removeAclEntries:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclEntriesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void removeDefaultAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #79,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.removeDefaultAcl:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveDefaultAclRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void removeAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #80,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.removeAcl:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #81,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setAcl:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$SetAclRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getAclStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #82,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getAclStatus:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$GetAclStatusRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setXAttr(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #83,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setXAttr:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$SetXAttrRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getXAttrs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #84,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getXAttrs:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$GetXAttrsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void listXAttrs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #85,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.listXAttrs:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$ListXAttrsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void removeXAttr(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #86,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.removeXAttr:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$RemoveXAttrRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void checkAccess(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #87,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.checkAccess:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CheckAccessRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void createEncryptionZone(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #88,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.createEncryptionZone:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$CreateEncryptionZoneRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void listEncryptionZones(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #89,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.listEncryptionZones:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListEncryptionZonesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void reencryptEncryptionZone(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #90,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.reencryptEncryptionZone:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void listReencryptionStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #91,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.listReencryptionStatus:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListReencryptionStatusRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getEZForPath(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #92,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getEZForPath:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$GetEZForPathRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void setErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #93,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.setErasureCodingPolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$SetErasureCodingPolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void unsetErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #94,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.unsetErasureCodingPolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getECTopologyResultForPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetECTopologyResultForPoliciesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetECTopologyResultForPoliciesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #95,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getECTopologyResultForPolicies:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetECTopologyResultForPoliciesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getCurrentEditLogTxid(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #96,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getCurrentEditLogTxid:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getEditsFromTxid(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #97,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getEditsFromTxid:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getErasureCodingPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #98,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getErasureCodingPolicies:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPoliciesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void addErasureCodingPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #99,  4           // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.addErasureCodingPolicies:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$AddErasureCodingPoliciesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void removeErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #100,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.removeErasureCodingPolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void enableErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #101,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.enableErasureCodingPolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$EnableErasureCodingPolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void disableErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #102,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.disableErasureCodingPolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$DisableErasureCodingPolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #103,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getErasureCodingPolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getErasureCodingCodecs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #104,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getErasureCodingCodecs:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingCodecsRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getQuotaUsage(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #105,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getQuotaUsage:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void listOpenFiles(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #106,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.listOpenFiles:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListOpenFilesRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void msync(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MsyncRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MsyncResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #107,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.msync:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MsyncRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void satisfyStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #108,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.satisfyStoragePolicy:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SatisfyStoragePolicyRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return

  public void getHAServiceState(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$HAServiceStateRequestProto, com.google.protobuf.RpcCallback<org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$HAServiceStateResponseProto>);
    Code:
       0: aload_0
       1: getfield      #1                  // Field val$impl:Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface;
       4: aload_1
       5: aload_2
       6: aload_3
       7: invokeinterface #109,  4          // InterfaceMethod org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface.getHAServiceState:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$HAServiceStateRequestProto;Lcom/google/protobuf/RpcCallback;)V
      12: return
}
