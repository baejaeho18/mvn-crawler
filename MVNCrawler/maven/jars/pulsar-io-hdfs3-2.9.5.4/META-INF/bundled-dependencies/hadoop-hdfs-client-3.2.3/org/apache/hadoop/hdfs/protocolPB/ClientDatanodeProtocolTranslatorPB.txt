Compiled from "ClientDatanodeProtocolTranslatorPB.java"
public class org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB implements org.apache.hadoop.ipc.ProtocolMetaInterface,org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol,org.apache.hadoop.ipc.ProtocolTranslator,java.io.Closeable {
  public static final org.slf4j.Logger LOG;

  private static final com.google.protobuf.RpcController NULL_CONTROLLER;

  private final org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB rpcProxy;

  private static final org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto VOID_REFRESH_NAMENODES;

  private static final org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto VOID_GET_DATANODE_INFO;

  private static final org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto VOID_GET_DATANODE_STORAGE_INFO;

  private static final org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto VOID_GET_RECONFIG_STATUS;

  private static final org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto VOID_START_RECONFIG;

  private static final org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto VOID_LIST_RECONFIGURABLE_PROPERTIES;

  private static final org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto VOID_GET_BALANCER_BANDWIDTH;

  private static final org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto VOID_EVICT_WRITERS;

  public org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.conf.Configuration, int, boolean, org.apache.hadoop.hdfs.protocol.LocatedBlock) throws java.io.IOException;
    Code:
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."<init>":()V
       4: aload_0
       5: aload_1
       6: aload_2
       7: iload_3
       8: iload         4
      10: aload         5
      12: invokestatic  #2                  // Method createClientDatanodeProtocolProxy:(Lorg/apache/hadoop/hdfs/protocol/DatanodeID;Lorg/apache/hadoop/conf/Configuration;IZLorg/apache/hadoop/hdfs/protocol/LocatedBlock;)Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      15: putfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      18: return

  public org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB(java.net.InetSocketAddress, org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.conf.Configuration, javax.net.SocketFactory) throws java.io.IOException;
    Code:
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."<init>":()V
       4: aload_0
       5: aload_1
       6: aload_2
       7: aload_3
       8: aload         4
      10: iconst_0
      11: invokestatic  #4                  // Method createClientDatanodeProtocolProxy:(Ljava/net/InetSocketAddress;Lorg/apache/hadoop/security/UserGroupInformation;Lorg/apache/hadoop/conf/Configuration;Ljavax/net/SocketFactory;I)Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      14: putfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      17: return

  public org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.conf.Configuration, int, boolean) throws java.io.IOException;
    Code:
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."<init>":()V
       4: aload_1
       5: iload         4
       7: invokevirtual #5                  // Method org/apache/hadoop/hdfs/protocol/DatanodeID.getIpcAddr:(Z)Ljava/lang/String;
      10: astore        5
      12: aload         5
      14: invokestatic  #6                  // Method org/apache/hadoop/net/NetUtils.createSocketAddr:(Ljava/lang/String;)Ljava/net/InetSocketAddress;
      17: astore        6
      19: getstatic     #7                  // Field LOG:Lorg/slf4j/Logger;
      22: ldc           #8                  // String Connecting to datanode {} addr={}
      24: aload         5
      26: aload         6
      28: invokeinterface #9,  4            // InterfaceMethod org/slf4j/Logger.debug:(Ljava/lang/String;Ljava/lang/Object;Ljava/lang/Object;)V
      33: aload_0
      34: aload         6
      36: invokestatic  #10                 // Method org/apache/hadoop/security/UserGroupInformation.getCurrentUser:()Lorg/apache/hadoop/security/UserGroupInformation;
      39: aload_2
      40: aload_2
      41: invokestatic  #11                 // Method org/apache/hadoop/net/NetUtils.getDefaultSocketFactory:(Lorg/apache/hadoop/conf/Configuration;)Ljavax/net/SocketFactory;
      44: iload_3
      45: invokestatic  #4                  // Method createClientDatanodeProtocolProxy:(Ljava/net/InetSocketAddress;Lorg/apache/hadoop/security/UserGroupInformation;Lorg/apache/hadoop/conf/Configuration;Ljavax/net/SocketFactory;I)Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      48: putfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      51: return

  static org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB createClientDatanodeProtocolProxy(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.conf.Configuration, int, boolean, org.apache.hadoop.hdfs.protocol.LocatedBlock) throws java.io.IOException;
    Code:
       0: aload_0
       1: iload_3
       2: invokevirtual #5                  // Method org/apache/hadoop/hdfs/protocol/DatanodeID.getIpcAddr:(Z)Ljava/lang/String;
       5: astore        5
       7: aload         5
       9: invokestatic  #6                  // Method org/apache/hadoop/net/NetUtils.createSocketAddr:(Ljava/lang/String;)Ljava/net/InetSocketAddress;
      12: astore        6
      14: getstatic     #7                  // Field LOG:Lorg/slf4j/Logger;
      17: ldc           #8                  // String Connecting to datanode {} addr={}
      19: aload         5
      21: aload         6
      23: invokeinterface #9,  4            // InterfaceMethod org/slf4j/Logger.debug:(Ljava/lang/String;Ljava/lang/Object;Ljava/lang/Object;)V
      28: new           #12                 // class org/apache/hadoop/conf/Configuration
      31: dup
      32: aload_1
      33: invokespecial #13                 // Method org/apache/hadoop/conf/Configuration."<init>":(Lorg/apache/hadoop/conf/Configuration;)V
      36: astore        7
      38: aload         7
      40: ldc           #15                 // String ipc.client.connection.maxidletime
      42: iconst_0
      43: invokevirtual #16                 // Method org/apache/hadoop/conf/Configuration.setInt:(Ljava/lang/String;I)V
      46: aload         4
      48: invokevirtual #17                 // Method org/apache/hadoop/hdfs/protocol/LocatedBlock.getBlock:()Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;
      51: invokevirtual #18                 // Method org/apache/hadoop/hdfs/protocol/ExtendedBlock.getLocalBlock:()Lorg/apache/hadoop/hdfs/protocol/Block;
      54: invokevirtual #19                 // Method org/apache/hadoop/hdfs/protocol/Block.toString:()Ljava/lang/String;
      57: invokestatic  #20                 // Method org/apache/hadoop/security/UserGroupInformation.createRemoteUser:(Ljava/lang/String;)Lorg/apache/hadoop/security/UserGroupInformation;
      60: astore        8
      62: aload         8
      64: aload         4
      66: invokevirtual #21                 // Method org/apache/hadoop/hdfs/protocol/LocatedBlock.getBlockToken:()Lorg/apache/hadoop/security/token/Token;
      69: invokevirtual #22                 // Method org/apache/hadoop/security/UserGroupInformation.addToken:(Lorg/apache/hadoop/security/token/Token;)Z
      72: pop
      73: aload         6
      75: aload         8
      77: aload         7
      79: aload_1
      80: invokestatic  #11                 // Method org/apache/hadoop/net/NetUtils.getDefaultSocketFactory:(Lorg/apache/hadoop/conf/Configuration;)Ljavax/net/SocketFactory;
      83: iload_2
      84: invokestatic  #4                  // Method createClientDatanodeProtocolProxy:(Ljava/net/InetSocketAddress;Lorg/apache/hadoop/security/UserGroupInformation;Lorg/apache/hadoop/conf/Configuration;Ljavax/net/SocketFactory;I)Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      87: areturn

  static org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB createClientDatanodeProtocolProxy(java.net.InetSocketAddress, org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.conf.Configuration, javax.net.SocketFactory, int) throws java.io.IOException;
    Code:
       0: aload_2
       1: ldc           #23                 // class org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB
       3: ldc           #24                 // class org/apache/hadoop/ipc/ProtobufRpcEngine
       5: invokestatic  #25                 // Method org/apache/hadoop/ipc/RPC.setProtocolEngine:(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/Class;Ljava/lang/Class;)V
       8: ldc           #23                 // class org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB
      10: ldc           #23                 // class org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB
      12: invokestatic  #26                 // Method org/apache/hadoop/ipc/RPC.getProtocolVersion:(Ljava/lang/Class;)J
      15: aload_0
      16: aload_1
      17: aload_2
      18: aload_3
      19: iload         4
      21: invokestatic  #27                 // Method org/apache/hadoop/ipc/RPC.getProxy:(Ljava/lang/Class;JLjava/net/InetSocketAddress;Lorg/apache/hadoop/security/UserGroupInformation;Lorg/apache/hadoop/conf/Configuration;Ljavax/net/SocketFactory;I)Ljava/lang/Object;
      24: checkcast     #23                 // class org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB
      27: areturn

  public void close();
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: invokestatic  #28                 // Method org/apache/hadoop/ipc/RPC.stopProxy:(Ljava/lang/Object;)V
       7: return

  public long getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.ExtendedBlock) throws java.io.IOException;
    Code:
       0: invokestatic  #29                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto$Builder;
       3: aload_1
       4: invokestatic  #30                 // Method org/apache/hadoop/hdfs/protocolPB/PBHelperClient.convert:(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;)Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$ExtendedBlockProto;
       7: invokevirtual #31                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto$Builder.setBlock:(Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$ExtendedBlockProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto$Builder;
      10: invokevirtual #32                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto;
      13: astore_2
      14: aload_0
      15: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      18: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      21: aload_2
      22: invokeinterface #34,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.getReplicaVisibleLength:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto;
      27: invokevirtual #35                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto.getLength:()J
      30: lreturn
      31: astore_3
      32: aload_3
      33: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      36: athrow
    Exception table:
       from    to  target type
          14    30    31   Class com/google/protobuf/ServiceException

  public void refreshNamenodes() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
       7: getstatic     #38                 // Field VOID_REFRESH_NAMENODES:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto;
      10: invokeinterface #39,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.refreshNamenodes:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto;
      15: pop
      16: goto          25
      19: astore_1
      20: aload_1
      21: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      24: athrow
      25: return
    Exception table:
       from    to  target type
           0    16    19   Class com/google/protobuf/ServiceException

  public void deleteBlockPool(java.lang.String, boolean) throws java.io.IOException;
    Code:
       0: invokestatic  #40                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder;
       3: aload_1
       4: invokevirtual #41                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder.setBlockPool:(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder;
       7: iload_2
       8: invokevirtual #42                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder.setForce:(Z)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder;
      11: invokevirtual #43                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto;
      14: astore_3
      15: aload_0
      16: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      19: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      22: aload_3
      23: invokeinterface #44,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.deleteBlockPool:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto;
      28: pop
      29: goto          40
      32: astore        4
      34: aload         4
      36: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      39: athrow
      40: return
    Exception table:
       from    to  target type
          15    29    32   Class com/google/protobuf/ServiceException

  public org.apache.hadoop.hdfs.protocol.BlockLocalPathInfo getBlockLocalPathInfo(org.apache.hadoop.hdfs.protocol.ExtendedBlock, org.apache.hadoop.security.token.Token<org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier>) throws java.io.IOException;
    Code:
       0: invokestatic  #45                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto$Builder;
       3: aload_1
       4: invokestatic  #30                 // Method org/apache/hadoop/hdfs/protocolPB/PBHelperClient.convert:(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;)Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$ExtendedBlockProto;
       7: invokevirtual #46                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto$Builder.setBlock:(Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$ExtendedBlockProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto$Builder;
      10: aload_2
      11: invokestatic  #47                 // Method org/apache/hadoop/hdfs/protocolPB/PBHelperClient.convert:(Lorg/apache/hadoop/security/token/Token;)Lorg/apache/hadoop/security/proto/SecurityProtos$TokenProto;
      14: invokevirtual #48                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto$Builder.setToken:(Lorg/apache/hadoop/security/proto/SecurityProtos$TokenProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto$Builder;
      17: invokevirtual #49                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto;
      20: astore_3
      21: aload_0
      22: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      25: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      28: aload_3
      29: invokeinterface #50,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.getBlockLocalPathInfo:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto;
      34: astore        4
      36: goto          47
      39: astore        5
      41: aload         5
      43: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      46: athrow
      47: new           #51                 // class org/apache/hadoop/hdfs/protocol/BlockLocalPathInfo
      50: dup
      51: aload         4
      53: invokevirtual #52                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto.getBlock:()Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$ExtendedBlockProto;
      56: invokestatic  #53                 // Method org/apache/hadoop/hdfs/protocolPB/PBHelperClient.convert:(Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$ExtendedBlockProto;)Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;
      59: aload         4
      61: invokevirtual #54                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto.getLocalPath:()Ljava/lang/String;
      64: aload         4
      66: invokevirtual #55                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto.getLocalMetaPath:()Ljava/lang/String;
      69: invokespecial #56                 // Method org/apache/hadoop/hdfs/protocol/BlockLocalPathInfo."<init>":(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;Ljava/lang/String;Ljava/lang/String;)V
      72: areturn
    Exception table:
       from    to  target type
          21    36    39   Class com/google/protobuf/ServiceException

  public boolean isMethodSupported(java.lang.String) throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: ldc           #23                 // class org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB
       6: getstatic     #57                 // Field org/apache/hadoop/ipc/RPC$RpcKind.RPC_PROTOCOL_BUFFER:Lorg/apache/hadoop/ipc/RPC$RpcKind;
       9: ldc           #23                 // class org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB
      11: invokestatic  #26                 // Method org/apache/hadoop/ipc/RPC.getProtocolVersion:(Ljava/lang/Class;)J
      14: aload_1
      15: invokestatic  #58                 // Method org/apache/hadoop/ipc/RpcClientUtil.isMethodSupported:(Ljava/lang/Object;Ljava/lang/Class;Lorg/apache/hadoop/ipc/RPC$RpcKind;JLjava/lang/String;)Z
      18: ireturn

  public java.lang.Object getUnderlyingProxyObject();
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: areturn

  public void shutdownDatanode(boolean) throws java.io.IOException;
    Code:
       0: invokestatic  #59                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder;
       3: iload_1
       4: invokevirtual #60                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder.setForUpgrade:(Z)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder;
       7: invokevirtual #61                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto;
      10: astore_2
      11: aload_0
      12: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      15: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      18: aload_2
      19: invokeinterface #62,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.shutdownDatanode:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto;
      24: pop
      25: goto          34
      28: astore_3
      29: aload_3
      30: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      33: athrow
      34: return
    Exception table:
       from    to  target type
          11    25    28   Class com/google/protobuf/ServiceException

  public void evictWriters() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
       7: getstatic     #63                 // Field VOID_EVICT_WRITERS:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto;
      10: invokeinterface #64,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.evictWriters:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersResponseProto;
      15: pop
      16: goto          25
      19: astore_1
      20: aload_1
      21: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      24: athrow
      25: return
    Exception table:
       from    to  target type
           0    16    19   Class com/google/protobuf/ServiceException

  public org.apache.hadoop.hdfs.protocol.DatanodeLocalInfo getDatanodeInfo() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
       7: getstatic     #65                 // Field VOID_GET_DATANODE_INFO:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto;
      10: invokeinterface #66,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.getDatanodeInfo:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto;
      15: astore_1
      16: aload_1
      17: invokevirtual #67                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto.getLocalInfo:()Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeLocalInfoProto;
      20: invokestatic  #68                 // Method org/apache/hadoop/hdfs/protocolPB/PBHelperClient.convert:(Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeLocalInfoProto;)Lorg/apache/hadoop/hdfs/protocol/DatanodeLocalInfo;
      23: areturn
      24: astore_2
      25: aload_2
      26: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      29: athrow
    Exception table:
       from    to  target type
           0    23    24   Class com/google/protobuf/ServiceException

  public void startReconfiguration() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
       7: getstatic     #69                 // Field VOID_START_RECONFIG:Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto;
      10: invokeinterface #70,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.startReconfiguration:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationResponseProto;
      15: pop
      16: goto          25
      19: astore_1
      20: aload_1
      21: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      24: athrow
      25: return
    Exception table:
       from    to  target type
           0    16    19   Class com/google/protobuf/ServiceException

  public org.apache.hadoop.conf.ReconfigurationTaskStatus getReconfigurationStatus() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
       7: getstatic     #71                 // Field VOID_GET_RECONFIG_STATUS:Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto;
      10: invokeinterface #72,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.getReconfigurationStatus:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto;
      15: invokestatic  #73                 // Method org/apache/hadoop/hdfs/protocolPB/ReconfigurationProtocolUtils.getReconfigurationStatus:(Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto;)Lorg/apache/hadoop/conf/ReconfigurationTaskStatus;
      18: areturn
      19: astore_1
      20: aload_1
      21: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      24: athrow
    Exception table:
       from    to  target type
           0    18    19   Class com/google/protobuf/ServiceException

  public java.util.List<java.lang.String> listReconfigurableProperties() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
       7: getstatic     #74                 // Field VOID_LIST_RECONFIGURABLE_PROPERTIES:Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto;
      10: invokeinterface #75,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.listReconfigurableProperties:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto;
      15: astore_1
      16: aload_1
      17: invokevirtual #76                 // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto.getNameList:()Ljava/util/List;
      20: areturn
      21: astore_2
      22: aload_2
      23: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      26: athrow
    Exception table:
       from    to  target type
           0    20    21   Class com/google/protobuf/ServiceException

  public void triggerBlockReport(org.apache.hadoop.hdfs.client.BlockReportOptions) throws java.io.IOException;
    Code:
       0: invokestatic  #77                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder;
       3: aload_1
       4: invokevirtual #78                 // Method org/apache/hadoop/hdfs/client/BlockReportOptions.isIncremental:()Z
       7: invokevirtual #79                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder.setIncremental:(Z)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder;
      10: astore_2
      11: aload_1
      12: invokevirtual #80                 // Method org/apache/hadoop/hdfs/client/BlockReportOptions.getNamenodeAddr:()Ljava/net/InetSocketAddress;
      15: ifnull        30
      18: aload_2
      19: aload_1
      20: invokevirtual #80                 // Method org/apache/hadoop/hdfs/client/BlockReportOptions.getNamenodeAddr:()Ljava/net/InetSocketAddress;
      23: invokestatic  #81                 // Method org/apache/hadoop/net/NetUtils.getHostPortString:(Ljava/net/InetSocketAddress;)Ljava/lang/String;
      26: invokevirtual #82                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder.setNnAddress:(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder;
      29: pop
      30: aload_0
      31: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      34: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      37: aload_2
      38: invokevirtual #83                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto;
      41: invokeinterface #84,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.triggerBlockReport:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto;
      46: pop
      47: goto          56
      50: astore_2
      51: aload_2
      52: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      55: athrow
      56: return
    Exception table:
       from    to  target type
           0    47    50   Class com/google/protobuf/ServiceException

  public long getBalancerBandwidth() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
       4: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
       7: getstatic     #85                 // Field VOID_GET_BALANCER_BANDWIDTH:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto;
      10: invokeinterface #86,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.getBalancerBandwidth:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto;
      15: astore_1
      16: aload_1
      17: invokevirtual #87                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto.getBandwidth:()J
      20: lreturn
      21: astore_2
      22: aload_2
      23: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      26: athrow
    Exception table:
       from    to  target type
           0    20    21   Class com/google/protobuf/ServiceException

  public void submitDiskBalancerPlan(java.lang.String, long, java.lang.String, java.lang.String, boolean) throws java.io.IOException;
    Code:
       0: invokestatic  #88                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder;
       3: aload_1
       4: invokevirtual #89                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder.setPlanID:(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder;
       7: lload_2
       8: invokevirtual #90                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder.setPlanVersion:(J)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder;
      11: aload         4
      13: invokevirtual #91                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder.setPlanFile:(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder;
      16: aload         5
      18: invokevirtual #92                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder.setPlan:(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder;
      21: iload         6
      23: invokevirtual #93                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder.setIgnoreDateCheck:(Z)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder;
      26: invokevirtual #94                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto;
      29: astore        7
      31: aload_0
      32: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      35: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      38: aload         7
      40: invokeinterface #95,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.submitDiskBalancerPlan:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto;
      45: pop
      46: goto          57
      49: astore        7
      51: aload         7
      53: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      56: athrow
      57: return
    Exception table:
       from    to  target type
           0    46    49   Class com/google/protobuf/ServiceException

  public void cancelDiskBalancePlan(java.lang.String) throws java.io.IOException;
    Code:
       0: invokestatic  #96                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder;
       3: aload_1
       4: invokevirtual #97                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder.setPlanID:(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder;
       7: invokevirtual #98                 // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto;
      10: astore_2
      11: aload_0
      12: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      15: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      18: aload_2
      19: invokeinterface #99,  3           // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.cancelDiskBalancerPlan:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanResponseProto;
      24: pop
      25: goto          34
      28: astore_2
      29: aload_2
      30: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      33: athrow
      34: return
    Exception table:
       from    to  target type
           0    25    28   Class com/google/protobuf/ServiceException

  public org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus queryDiskBalancerPlan() throws java.io.IOException;
    Code:
       0: invokestatic  #100                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder;
       3: invokevirtual #101                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto;
       6: astore_1
       7: aload_0
       8: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      11: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      14: aload_1
      15: invokeinterface #102,  3          // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.queryDiskBalancerPlan:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto;
      20: astore_2
      21: getstatic     #103                // Field org/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus$Result.NO_PLAN:Lorg/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus$Result;
      24: astore_3
      25: aload_2
      26: invokevirtual #104                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.hasResult:()Z
      29: ifeq          41
      32: invokestatic  #105                // Method org/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus$Result.values:()[Lorg/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus$Result;
      35: aload_2
      36: invokevirtual #106                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.getResult:()I
      39: aaload
      40: astore_3
      41: new           #107                // class org/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus
      44: dup
      45: aload_3
      46: aload_2
      47: invokevirtual #108                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.hasPlanID:()Z
      50: ifeq          60
      53: aload_2
      54: invokevirtual #109                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.getPlanID:()Ljava/lang/String;
      57: goto          61
      60: aconst_null
      61: aload_2
      62: invokevirtual #110                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.hasPlanFile:()Z
      65: ifeq          75
      68: aload_2
      69: invokevirtual #111                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.getPlanFile:()Ljava/lang/String;
      72: goto          76
      75: aconst_null
      76: aload_2
      77: invokevirtual #112                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.hasCurrentStatus:()Z
      80: ifeq          90
      83: aload_2
      84: invokevirtual #113                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.getCurrentStatus:()Ljava/lang/String;
      87: goto          91
      90: aconst_null
      91: invokespecial #114                // Method org/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus."<init>":(Lorg/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus$Result;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V
      94: areturn
      95: astore_1
      96: aload_1
      97: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
     100: athrow
    Exception table:
       from    to  target type
           0    94    95   Class com/google/protobuf/ServiceException

  public java.lang.String getDiskBalancerSetting(java.lang.String) throws java.io.IOException;
    Code:
       0: invokestatic  #115                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder;
       3: aload_1
       4: invokevirtual #116                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder.setKey:(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder;
       7: invokevirtual #117                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto;
      10: astore_2
      11: aload_0
      12: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      15: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      18: aload_2
      19: invokeinterface #118,  3          // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.getDiskBalancerSetting:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto;
      24: astore_3
      25: aload_3
      26: invokevirtual #119                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto.hasValue:()Z
      29: ifeq          39
      32: aload_3
      33: invokevirtual #120                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto.getValue:()Ljava/lang/String;
      36: goto          40
      39: aconst_null
      40: areturn
      41: astore_2
      42: aload_2
      43: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
      46: athrow
    Exception table:
       from    to  target type
           0    40    41   Class com/google/protobuf/ServiceException

  public java.util.List<org.apache.hadoop.hdfs.protocol.DatanodeVolumeInfo> getVolumeReport() throws java.io.IOException;
    Code:
       0: new           #121                // class java/util/ArrayList
       3: dup
       4: invokespecial #122                // Method java/util/ArrayList."<init>":()V
       7: astore_1
       8: aload_0
       9: getfield      #3                  // Field rpcProxy:Lorg/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB;
      12: getstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      15: getstatic     #123                // Field VOID_GET_DATANODE_STORAGE_INFO:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto;
      18: invokeinterface #124,  3          // InterfaceMethod org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.getVolumeReport:(Lcom/google/protobuf/RpcController;Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto;)Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportResponseProto;
      23: astore_2
      24: aload_2
      25: invokevirtual #125                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportResponseProto.getVolumeInfoList:()Ljava/util/List;
      28: astore_3
      29: aload_3
      30: invokeinterface #126,  1          // InterfaceMethod java/util/List.iterator:()Ljava/util/Iterator;
      35: astore        4
      37: aload         4
      39: invokeinterface #127,  1          // InterfaceMethod java/util/Iterator.hasNext:()Z
      44: ifeq          114
      47: aload         4
      49: invokeinterface #128,  1          // InterfaceMethod java/util/Iterator.next:()Ljava/lang/Object;
      54: checkcast     #129                // class org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeVolumeInfoProto
      57: astore        5
      59: aload_1
      60: new           #130                // class org/apache/hadoop/hdfs/protocol/DatanodeVolumeInfo
      63: dup
      64: aload         5
      66: invokevirtual #131                // Method org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeVolumeInfoProto.getPath:()Ljava/lang/String;
      69: aload         5
      71: invokevirtual #132                // Method org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeVolumeInfoProto.getUsedSpace:()J
      74: aload         5
      76: invokevirtual #133                // Method org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeVolumeInfoProto.getFreeSpace:()J
      79: aload         5
      81: invokevirtual #134                // Method org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeVolumeInfoProto.getReservedSpace:()J
      84: aload         5
      86: invokevirtual #135                // Method org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeVolumeInfoProto.getReservedSpaceForReplicas:()J
      89: aload         5
      91: invokevirtual #136                // Method org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeVolumeInfoProto.getNumBlocks:()J
      94: aload         5
      96: invokevirtual #137                // Method org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeVolumeInfoProto.getStorageType:()Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$StorageTypeProto;
      99: invokestatic  #138                // Method org/apache/hadoop/hdfs/protocolPB/PBHelperClient.convertStorageType:(Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$StorageTypeProto;)Lorg/apache/hadoop/fs/StorageType;
     102: invokespecial #139                // Method org/apache/hadoop/hdfs/protocol/DatanodeVolumeInfo."<init>":(Ljava/lang/String;JJJJJLorg/apache/hadoop/fs/StorageType;)V
     105: invokeinterface #140,  2          // InterfaceMethod java/util/List.add:(Ljava/lang/Object;)Z
     110: pop
     111: goto          37
     114: aload_1
     115: areturn
     116: astore_1
     117: aload_1
     118: invokestatic  #37                 // Method org/apache/hadoop/ipc/ProtobufHelper.getRemoteException:(Lcom/google/protobuf/ServiceException;)Ljava/io/IOException;
     121: athrow
    Exception table:
       from    to  target type
           0   115   116   Class com/google/protobuf/ServiceException

  static {};
    Code:
       0: ldc           #141                // class org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB
       2: invokestatic  #142                // Method org/slf4j/LoggerFactory.getLogger:(Ljava/lang/Class;)Lorg/slf4j/Logger;
       5: putstatic     #7                  // Field LOG:Lorg/slf4j/Logger;
       8: aconst_null
       9: putstatic     #33                 // Field NULL_CONTROLLER:Lcom/google/protobuf/RpcController;
      12: invokestatic  #143                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder;
      15: invokevirtual #144                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto;
      18: putstatic     #38                 // Field VOID_REFRESH_NAMENODES:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto;
      21: invokestatic  #145                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder;
      24: invokevirtual #146                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto;
      27: putstatic     #65                 // Field VOID_GET_DATANODE_INFO:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto;
      30: invokestatic  #147                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder;
      33: invokevirtual #148                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto;
      36: putstatic     #123                // Field VOID_GET_DATANODE_STORAGE_INFO:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto;
      39: invokestatic  #149                // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder;
      42: invokevirtual #150                // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto;
      45: putstatic     #71                 // Field VOID_GET_RECONFIG_STATUS:Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto;
      48: invokestatic  #151                // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder;
      51: invokevirtual #152                // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto;
      54: putstatic     #69                 // Field VOID_START_RECONFIG:Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto;
      57: invokestatic  #153                // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder;
      60: invokevirtual #154                // Method org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto;
      63: putstatic     #74                 // Field VOID_LIST_RECONFIGURABLE_PROPERTIES:Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto;
      66: invokestatic  #155                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder;
      69: invokevirtual #156                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto;
      72: putstatic     #85                 // Field VOID_GET_BALANCER_BANDWIDTH:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto;
      75: invokestatic  #157                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto.newBuilder:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder;
      78: invokevirtual #158                // Method org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder.build:()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto;
      81: putstatic     #63                 // Field VOID_EVICT_WRITERS:Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto;
      84: return
}
