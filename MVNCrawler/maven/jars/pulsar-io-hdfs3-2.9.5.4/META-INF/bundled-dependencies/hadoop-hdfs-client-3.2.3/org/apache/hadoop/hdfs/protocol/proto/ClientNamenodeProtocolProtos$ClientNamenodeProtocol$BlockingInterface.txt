Compiled from "ClientNamenodeProtocolProtos.java"
public interface org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$BlockingInterface {
  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto getBlockLocations(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto getServerDefaults(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto create(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto append(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto setReplication(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto setStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto unsetStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto getStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto getStoragePolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto setPermission(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto setOwner(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto abandonBlock(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto addBlock(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto getAdditionalDatanode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto complete(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto reportBadBlocks(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto concat(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto truncate(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto rename(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto rename2(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto delete(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto mkdirs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto getListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto renewLease(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto recoverLease(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto getFsStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto getFsReplicatedBlockStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto getFsECBlockGroupStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto getDatanodeReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto getDatanodeStorageReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto getPreferredBlockSize(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto setSafeMode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto saveNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto rollEdits(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto restoreFailedStorage(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto refreshNodes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto finalizeUpgrade(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto upgradeStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto rollingUpgrade(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto listCorruptFileBlocks(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto metaSave(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto getFileInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto getLocatedFileInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto addCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto modifyCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto removeCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto listCacheDirectives(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto addCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto modifyCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto removeCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto listCachePools(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto getFileLinkInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto getContentSummary(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto setQuota(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto fsync(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto setTimes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto createSymlink(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto getLinkTarget(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto updateBlockForPipeline(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto updatePipeline(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenResponseProto getDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenResponseProto renewDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenResponseProto cancelDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto setBalancerBandwidth(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto getDataEncryptionKey(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto createSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto renameSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto allowSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto disallowSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto getSnapshottableDirListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto deleteSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto getSnapshotDiffReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto getSnapshotDiffReportListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto isFileClosed(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto modifyAclEntries(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto removeAclEntries(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto removeDefaultAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto removeAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto setAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto getAclStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto setXAttr(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto getXAttrs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto listXAttrs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto removeXAttr(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto checkAccess(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto createEncryptionZone(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto listEncryptionZones(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto reencryptEncryptionZone(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto listReencryptionStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto getEZForPath(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto setErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto unsetErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetECTopologyResultForPoliciesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto getCurrentEditLogTxid(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto getEditsFromTxid(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto getErasureCodingPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto addErasureCodingPolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto removeErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto enableErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto disableErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto getErasureCodingPolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto getErasureCodingCodecs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto getQuotaUsage(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto listOpenFiles(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MsyncResponseProto msync(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MsyncRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyResponseProto satisfyStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyRequestProto) throws com.google.protobuf.ServiceException;

  public abstract org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$HAServiceStateResponseProto getHAServiceState(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$HAServiceStateRequestProto) throws com.google.protobuf.ServiceException;
}
