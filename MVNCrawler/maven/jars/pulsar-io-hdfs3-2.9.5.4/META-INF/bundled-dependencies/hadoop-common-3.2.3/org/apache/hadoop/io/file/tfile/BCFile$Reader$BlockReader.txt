Compiled from "BCFile.java"
public class org.apache.hadoop.io.file.tfile.BCFile$Reader$BlockReader extends java.io.DataInputStream {
  private final org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState rBlkState;

  private boolean closed;

  org.apache.hadoop.io.file.tfile.BCFile$Reader$BlockReader(org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState);
    Code:
       0: aload_0
       1: aload_1
       2: invokevirtual #1                  // Method org/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState.getInputStream:()Ljava/io/InputStream;
       5: invokespecial #2                  // Method java/io/DataInputStream."<init>":(Ljava/io/InputStream;)V
       8: aload_0
       9: iconst_0
      10: putfield      #3                  // Field closed:Z
      13: aload_0
      14: aload_1
      15: putfield      #4                  // Field rBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState;
      18: return

  public void close() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field closed:Z
       4: iconst_1
       5: if_icmpne     9
       8: return
       9: aload_0
      10: getfield      #4                  // Field rBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState;
      13: invokevirtual #5                  // Method org/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState.finish:()V
      16: aload_0
      17: iconst_1
      18: putfield      #3                  // Field closed:Z
      21: goto          32
      24: astore_1
      25: aload_0
      26: iconst_1
      27: putfield      #3                  // Field closed:Z
      30: aload_1
      31: athrow
      32: return
    Exception table:
       from    to  target type
           9    16    24   any

  public java.lang.String getCompressionName();
    Code:
       0: aload_0
       1: getfield      #4                  // Field rBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState;
       4: invokevirtual #6                  // Method org/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState.getCompressionName:()Ljava/lang/String;
       7: areturn

  public long getRawSize();
    Code:
       0: aload_0
       1: getfield      #4                  // Field rBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState;
       4: invokevirtual #7                  // Method org/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState.getBlockRegion:()Lorg/apache/hadoop/io/file/tfile/BCFile$BlockRegion;
       7: invokevirtual #8                  // Method org/apache/hadoop/io/file/tfile/BCFile$BlockRegion.getRawSize:()J
      10: lreturn

  public long getCompressedSize();
    Code:
       0: aload_0
       1: getfield      #4                  // Field rBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState;
       4: invokevirtual #7                  // Method org/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState.getBlockRegion:()Lorg/apache/hadoop/io/file/tfile/BCFile$BlockRegion;
       7: invokevirtual #9                  // Method org/apache/hadoop/io/file/tfile/BCFile$BlockRegion.getCompressedSize:()J
      10: lreturn

  public long getStartPos();
    Code:
       0: aload_0
       1: getfield      #4                  // Field rBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState;
       4: invokevirtual #7                  // Method org/apache/hadoop/io/file/tfile/BCFile$Reader$RBlockState.getBlockRegion:()Lorg/apache/hadoop/io/file/tfile/BCFile$BlockRegion;
       7: invokevirtual #10                 // Method org/apache/hadoop/io/file/tfile/BCFile$BlockRegion.getOffset:()J
      10: lreturn
}
