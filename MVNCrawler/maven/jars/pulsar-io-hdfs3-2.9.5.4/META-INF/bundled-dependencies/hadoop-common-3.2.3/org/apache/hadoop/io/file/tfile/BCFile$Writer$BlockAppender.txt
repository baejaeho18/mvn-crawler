Compiled from "BCFile.java"
public class org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender extends java.io.DataOutputStream {
  private final org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockRegister blockRegister;

  private final org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState wBlkState;

  private boolean closed;

  final org.apache.hadoop.io.file.tfile.BCFile$Writer this$0;

  org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender(org.apache.hadoop.io.file.tfile.BCFile$Writer, org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockRegister, org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState);
    Code:
       0: aload_0
       1: aload_1
       2: putfield      #1                  // Field this$0:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer;
       5: aload_0
       6: aload_3
       7: invokevirtual #2                  // Method org/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState.getOutputStream:()Ljava/io/OutputStream;
      10: invokespecial #3                  // Method java/io/DataOutputStream."<init>":(Ljava/io/OutputStream;)V
      13: aload_0
      14: iconst_0
      15: putfield      #4                  // Field closed:Z
      18: aload_0
      19: aload_2
      20: putfield      #5                  // Field blockRegister:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer$BlockRegister;
      23: aload_0
      24: aload_3
      25: putfield      #6                  // Field wBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState;
      28: return

  public long getRawSize() throws java.io.IOException;
    Code:
       0: aload_0
       1: invokevirtual #7                  // Method size:()I
       4: i2l
       5: ldc2_w        #8                  // long 4294967295l
       8: land
       9: lreturn

  public long getCompressedSize() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #6                  // Field wBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState;
       4: invokevirtual #10                 // Method org/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState.getCompressedSize:()J
       7: lreturn

  public void flush();
    Code:
       0: return

  public void close() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field closed:Z
       4: iconst_1
       5: if_icmpne     9
       8: return
       9: aload_0
      10: getfield      #1                  // Field this$0:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer;
      13: dup
      14: getfield      #11                 // Field org/apache/hadoop/io/file/tfile/BCFile$Writer.errorCount:J
      17: lconst_1
      18: ladd
      19: putfield      #11                 // Field org/apache/hadoop/io/file/tfile/BCFile$Writer.errorCount:J
      22: aload_0
      23: getfield      #6                  // Field wBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState;
      26: invokevirtual #12                 // Method org/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState.finish:()V
      29: aload_0
      30: getfield      #5                  // Field blockRegister:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer$BlockRegister;
      33: aload_0
      34: invokevirtual #13                 // Method getRawSize:()J
      37: aload_0
      38: getfield      #6                  // Field wBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState;
      41: invokevirtual #14                 // Method org/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState.getStartPos:()J
      44: aload_0
      45: getfield      #6                  // Field wBlkState:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState;
      48: invokevirtual #15                 // Method org/apache/hadoop/io/file/tfile/BCFile$Writer$WBlockState.getCurrentPos:()J
      51: invokeinterface #16,  7           // InterfaceMethod org/apache/hadoop/io/file/tfile/BCFile$Writer$BlockRegister.register:(JJJ)V
      56: aload_0
      57: getfield      #1                  // Field this$0:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer;
      60: dup
      61: getfield      #11                 // Field org/apache/hadoop/io/file/tfile/BCFile$Writer.errorCount:J
      64: lconst_1
      65: lsub
      66: putfield      #11                 // Field org/apache/hadoop/io/file/tfile/BCFile$Writer.errorCount:J
      69: aload_0
      70: iconst_1
      71: putfield      #4                  // Field closed:Z
      74: aload_0
      75: getfield      #1                  // Field this$0:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer;
      78: iconst_0
      79: putfield      #17                 // Field org/apache/hadoop/io/file/tfile/BCFile$Writer.blkInProgress:Z
      82: goto          101
      85: astore_1
      86: aload_0
      87: iconst_1
      88: putfield      #4                  // Field closed:Z
      91: aload_0
      92: getfield      #1                  // Field this$0:Lorg/apache/hadoop/io/file/tfile/BCFile$Writer;
      95: iconst_0
      96: putfield      #17                 // Field org/apache/hadoop/io/file/tfile/BCFile$Writer.blkInProgress:Z
      99: aload_1
     100: athrow
     101: return
    Exception table:
       from    to  target type
           9    69    85   any
}
