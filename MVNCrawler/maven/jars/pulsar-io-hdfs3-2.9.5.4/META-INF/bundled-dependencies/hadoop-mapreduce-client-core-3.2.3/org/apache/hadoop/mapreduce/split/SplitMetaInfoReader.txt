Compiled from "SplitMetaInfoReader.java"
public class org.apache.hadoop.mapreduce.split.SplitMetaInfoReader {
  public org.apache.hadoop.mapreduce.split.SplitMetaInfoReader();
    Code:
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."<init>":()V
       4: return

  public static org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo[] readSplitMetaInfo(org.apache.hadoop.mapreduce.JobID, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path) throws java.io.IOException;
    Code:
       0: aload_2
       1: ldc           #3                  // String mapreduce.job.split.metainfo.maxsize
       3: ldc2_w        #4                  // long 10000000l
       6: invokevirtual #6                  // Method org/apache/hadoop/conf/Configuration.getLong:(Ljava/lang/String;J)J
       9: lstore        4
      11: aload_3
      12: invokestatic  #7                  // Method org/apache/hadoop/mapreduce/JobSubmissionFiles.getJobSplitMetaFile:(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path;
      15: astore        6
      17: aload_3
      18: invokestatic  #8                  // Method org/apache/hadoop/mapreduce/JobSubmissionFiles.getJobSplitFile:(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path;
      21: invokevirtual #9                  // Method org/apache/hadoop/fs/Path.toString:()Ljava/lang/String;
      24: astore        7
      26: aload_1
      27: aload         6
      29: invokevirtual #10                 // Method org/apache/hadoop/fs/FileSystem.getFileStatus:(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/FileStatus;
      32: astore        8
      34: lload         4
      36: lconst_0
      37: lcmp
      38: ifle          89
      41: aload         8
      43: invokevirtual #11                 // Method org/apache/hadoop/fs/FileStatus.getLen:()J
      46: lload         4
      48: lcmp
      49: ifle          89
      52: new           #12                 // class java/io/IOException
      55: dup
      56: new           #13                 // class java/lang/StringBuilder
      59: dup
      60: invokespecial #14                 // Method java/lang/StringBuilder."<init>":()V
      63: ldc           #15                 // String Split metadata size exceeded
      65: invokevirtual #16                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
      68: lload         4
      70: invokevirtual #17                 // Method java/lang/StringBuilder.append:(J)Ljava/lang/StringBuilder;
      73: ldc           #18                 // String . Aborting job
      75: invokevirtual #16                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
      78: aload_0
      79: invokevirtual #19                 // Method java/lang/StringBuilder.append:(Ljava/lang/Object;)Ljava/lang/StringBuilder;
      82: invokevirtual #20                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;
      85: invokespecial #21                 // Method java/io/IOException."<init>":(Ljava/lang/String;)V
      88: athrow
      89: aload_1
      90: aload         6
      92: invokevirtual #22                 // Method org/apache/hadoop/fs/FileSystem.open:(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/FSDataInputStream;
      95: astore        9
      97: getstatic     #23                 // Field org/apache/hadoop/mapreduce/split/JobSplit.META_SPLIT_FILE_HEADER:[B
     100: arraylength
     101: newarray       byte
     103: astore        10
     105: aload         9
     107: aload         10
     109: invokevirtual #24                 // Method org/apache/hadoop/fs/FSDataInputStream.readFully:([B)V
     112: getstatic     #23                 // Field org/apache/hadoop/mapreduce/split/JobSplit.META_SPLIT_FILE_HEADER:[B
     115: aload         10
     117: invokestatic  #25                 // Method java/util/Arrays.equals:([B[B)Z
     120: ifne          133
     123: new           #12                 // class java/io/IOException
     126: dup
     127: ldc           #26                 // String Invalid header on split file
     129: invokespecial #21                 // Method java/io/IOException."<init>":(Ljava/lang/String;)V
     132: athrow
     133: aload         9
     135: invokestatic  #27                 // Method org/apache/hadoop/io/WritableUtils.readVInt:(Ljava/io/DataInput;)I
     138: istore        11
     140: iload         11
     142: iconst_1
     143: if_icmpeq     179
     146: aload         9
     148: invokevirtual #29                 // Method org/apache/hadoop/fs/FSDataInputStream.close:()V
     151: new           #12                 // class java/io/IOException
     154: dup
     155: new           #13                 // class java/lang/StringBuilder
     158: dup
     159: invokespecial #14                 // Method java/lang/StringBuilder."<init>":()V
     162: ldc           #30                 // String Unsupported split version
     164: invokevirtual #16                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
     167: iload         11
     169: invokevirtual #31                 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;
     172: invokevirtual #20                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;
     175: invokespecial #21                 // Method java/io/IOException."<init>":(Ljava/lang/String;)V
     178: athrow
     179: aload         9
     181: invokestatic  #27                 // Method org/apache/hadoop/io/WritableUtils.readVInt:(Ljava/io/DataInput;)I
     184: istore        12
     186: iload         12
     188: anewarray     #32                 // class org/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo
     191: astore        13
     193: iconst_0
     194: istore        14
     196: iload         14
     198: iload         12
     200: if_icmpge     265
     203: new           #33                 // class org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo
     206: dup
     207: invokespecial #34                 // Method org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo."<init>":()V
     210: astore        15
     212: aload         15
     214: aload         9
     216: invokevirtual #35                 // Method org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo.readFields:(Ljava/io/DataInput;)V
     219: new           #36                 // class org/apache/hadoop/mapreduce/split/JobSplit$TaskSplitIndex
     222: dup
     223: aload         7
     225: aload         15
     227: invokevirtual #37                 // Method org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo.getStartOffset:()J
     230: invokespecial #38                 // Method org/apache/hadoop/mapreduce/split/JobSplit$TaskSplitIndex."<init>":(Ljava/lang/String;J)V
     233: astore        16
     235: aload         13
     237: iload         14
     239: new           #32                 // class org/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo
     242: dup
     243: aload         16
     245: aload         15
     247: invokevirtual #39                 // Method org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo.getLocations:()[Ljava/lang/String;
     250: aload         15
     252: invokevirtual #40                 // Method org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo.getInputDataLength:()J
     255: invokespecial #41                 // Method org/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo."<init>":(Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitIndex;[Ljava/lang/String;J)V
     258: aastore
     259: iinc          14, 1
     262: goto          196
     265: aload         9
     267: invokevirtual #29                 // Method org/apache/hadoop/fs/FSDataInputStream.close:()V
     270: aload         13
     272: areturn
}
