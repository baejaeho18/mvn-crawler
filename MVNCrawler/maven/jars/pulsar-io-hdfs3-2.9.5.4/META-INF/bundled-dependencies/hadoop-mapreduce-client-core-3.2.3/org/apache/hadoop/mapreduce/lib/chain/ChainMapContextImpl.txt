Compiled from "ChainMapContextImpl.java"
class org.apache.hadoop.mapreduce.lib.chain.ChainMapContextImpl<KEYIN, VALUEIN, KEYOUT, VALUEOUT> implements org.apache.hadoop.mapreduce.MapContext<KEYIN, VALUEIN, KEYOUT, VALUEOUT> {
  private org.apache.hadoop.mapreduce.RecordReader<KEYIN, VALUEIN> reader;

  private org.apache.hadoop.mapreduce.RecordWriter<KEYOUT, VALUEOUT> output;

  private org.apache.hadoop.mapreduce.TaskInputOutputContext<KEYIN, VALUEIN, KEYOUT, VALUEOUT> base;

  private org.apache.hadoop.conf.Configuration conf;

  org.apache.hadoop.mapreduce.lib.chain.ChainMapContextImpl(org.apache.hadoop.mapreduce.TaskInputOutputContext<KEYIN, VALUEIN, KEYOUT, VALUEOUT>, org.apache.hadoop.mapreduce.RecordReader<KEYIN, VALUEIN>, org.apache.hadoop.mapreduce.RecordWriter<KEYOUT, VALUEOUT>, org.apache.hadoop.conf.Configuration);
    Code:
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."<init>":()V
       4: aload_0
       5: aload_2
       6: putfield      #2                  // Field reader:Lorg/apache/hadoop/mapreduce/RecordReader;
       9: aload_0
      10: aload_3
      11: putfield      #3                  // Field output:Lorg/apache/hadoop/mapreduce/RecordWriter;
      14: aload_0
      15: aload_1
      16: putfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
      19: aload_0
      20: aload         4
      22: putfield      #5                  // Field conf:Lorg/apache/hadoop/conf/Configuration;
      25: return

  public KEYIN getCurrentKey() throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_0
       1: getfield      #2                  // Field reader:Lorg/apache/hadoop/mapreduce/RecordReader;
       4: invokevirtual #6                  // Method org/apache/hadoop/mapreduce/RecordReader.getCurrentKey:()Ljava/lang/Object;
       7: areturn

  public VALUEIN getCurrentValue() throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_0
       1: getfield      #2                  // Field reader:Lorg/apache/hadoop/mapreduce/RecordReader;
       4: invokevirtual #7                  // Method org/apache/hadoop/mapreduce/RecordReader.getCurrentValue:()Ljava/lang/Object;
       7: areturn

  public boolean nextKeyValue() throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_0
       1: getfield      #2                  // Field reader:Lorg/apache/hadoop/mapreduce/RecordReader;
       4: invokevirtual #8                  // Method org/apache/hadoop/mapreduce/RecordReader.nextKeyValue:()Z
       7: ireturn

  public org.apache.hadoop.mapreduce.InputSplit getInputSplit();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: instanceof    #9                  // class org/apache/hadoop/mapreduce/MapContext
       7: ifeq          25
      10: aload_0
      11: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
      14: checkcast     #9                  // class org/apache/hadoop/mapreduce/MapContext
      17: astore_1
      18: aload_1
      19: invokeinterface #10,  1           // InterfaceMethod org/apache/hadoop/mapreduce/MapContext.getInputSplit:()Lorg/apache/hadoop/mapreduce/InputSplit;
      24: areturn
      25: aconst_null
      26: areturn

  public org.apache.hadoop.mapreduce.Counter getCounter(java.lang.Enum<?>);
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: aload_1
       5: invokeinterface #11,  2           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCounter:(Ljava/lang/Enum;)Lorg/apache/hadoop/mapreduce/Counter;
      10: areturn

  public org.apache.hadoop.mapreduce.Counter getCounter(java.lang.String, java.lang.String);
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: aload_1
       5: aload_2
       6: invokeinterface #12,  3           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCounter:(Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/Counter;
      11: areturn

  public org.apache.hadoop.mapreduce.OutputCommitter getOutputCommitter();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #13,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getOutputCommitter:()Lorg/apache/hadoop/mapreduce/OutputCommitter;
       9: areturn

  public void write(KEYOUT, VALUEOUT) throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field output:Lorg/apache/hadoop/mapreduce/RecordWriter;
       4: aload_1
       5: aload_2
       6: invokevirtual #14                 // Method org/apache/hadoop/mapreduce/RecordWriter.write:(Ljava/lang/Object;Ljava/lang/Object;)V
       9: return

  public java.lang.String getStatus();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #15,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getStatus:()Ljava/lang/String;
       9: areturn

  public org.apache.hadoop.mapreduce.TaskAttemptID getTaskAttemptID();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #16,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getTaskAttemptID:()Lorg/apache/hadoop/mapreduce/TaskAttemptID;
       9: areturn

  public void setStatus(java.lang.String);
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: aload_1
       5: invokeinterface #17,  2           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.setStatus:(Ljava/lang/String;)V
      10: return

  public org.apache.hadoop.fs.Path[] getArchiveClassPaths();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #18,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getArchiveClassPaths:()[Lorg/apache/hadoop/fs/Path;
       9: areturn

  public java.lang.String[] getArchiveTimestamps();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #19,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getArchiveTimestamps:()[Ljava/lang/String;
       9: areturn

  public java.net.URI[] getCacheArchives() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #20,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCacheArchives:()[Ljava/net/URI;
       9: areturn

  public java.net.URI[] getCacheFiles() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #21,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCacheFiles:()[Ljava/net/URI;
       9: areturn

  public java.lang.Class<? extends org.apache.hadoop.mapreduce.Reducer<?, ?, ?, ?>> getCombinerClass() throws java.lang.ClassNotFoundException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #22,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCombinerClass:()Ljava/lang/Class;
       9: areturn

  public org.apache.hadoop.conf.Configuration getConfiguration();
    Code:
       0: aload_0
       1: getfield      #5                  // Field conf:Lorg/apache/hadoop/conf/Configuration;
       4: areturn

  public org.apache.hadoop.fs.Path[] getFileClassPaths();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #23,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getFileClassPaths:()[Lorg/apache/hadoop/fs/Path;
       9: areturn

  public java.lang.String[] getFileTimestamps();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #24,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getFileTimestamps:()[Ljava/lang/String;
       9: areturn

  public org.apache.hadoop.io.RawComparator<?> getCombinerKeyGroupingComparator();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #25,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCombinerKeyGroupingComparator:()Lorg/apache/hadoop/io/RawComparator;
       9: areturn

  public org.apache.hadoop.io.RawComparator<?> getGroupingComparator();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #26,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getGroupingComparator:()Lorg/apache/hadoop/io/RawComparator;
       9: areturn

  public java.lang.Class<? extends org.apache.hadoop.mapreduce.InputFormat<?, ?>> getInputFormatClass() throws java.lang.ClassNotFoundException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #27,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getInputFormatClass:()Ljava/lang/Class;
       9: areturn

  public java.lang.String getJar();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #28,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getJar:()Ljava/lang/String;
       9: areturn

  public org.apache.hadoop.mapreduce.JobID getJobID();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #29,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getJobID:()Lorg/apache/hadoop/mapreduce/JobID;
       9: areturn

  public java.lang.String getJobName();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #30,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getJobName:()Ljava/lang/String;
       9: areturn

  public boolean getJobSetupCleanupNeeded();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #31,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getJobSetupCleanupNeeded:()Z
       9: ireturn

  public boolean getTaskCleanupNeeded();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #32,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getTaskCleanupNeeded:()Z
       9: ireturn

  public org.apache.hadoop.fs.Path[] getLocalCacheArchives() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #33,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getLocalCacheArchives:()[Lorg/apache/hadoop/fs/Path;
       9: areturn

  public org.apache.hadoop.fs.Path[] getLocalCacheFiles() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #33,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getLocalCacheArchives:()[Lorg/apache/hadoop/fs/Path;
       9: areturn

  public java.lang.Class<?> getMapOutputKeyClass();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #34,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getMapOutputKeyClass:()Ljava/lang/Class;
       9: areturn

  public java.lang.Class<?> getMapOutputValueClass();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #35,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getMapOutputValueClass:()Ljava/lang/Class;
       9: areturn

  public java.lang.Class<? extends org.apache.hadoop.mapreduce.Mapper<?, ?, ?, ?>> getMapperClass() throws java.lang.ClassNotFoundException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #36,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getMapperClass:()Ljava/lang/Class;
       9: areturn

  public int getMaxMapAttempts();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #37,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getMaxMapAttempts:()I
       9: ireturn

  public int getMaxReduceAttempts();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #38,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getMaxReduceAttempts:()I
       9: ireturn

  public int getNumReduceTasks();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #39,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getNumReduceTasks:()I
       9: ireturn

  public java.lang.Class<? extends org.apache.hadoop.mapreduce.OutputFormat<?, ?>> getOutputFormatClass() throws java.lang.ClassNotFoundException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #40,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getOutputFormatClass:()Ljava/lang/Class;
       9: areturn

  public java.lang.Class<?> getOutputKeyClass();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #34,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getMapOutputKeyClass:()Ljava/lang/Class;
       9: areturn

  public java.lang.Class<?> getOutputValueClass();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #41,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getOutputValueClass:()Ljava/lang/Class;
       9: areturn

  public java.lang.Class<? extends org.apache.hadoop.mapreduce.Partitioner<?, ?>> getPartitionerClass() throws java.lang.ClassNotFoundException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #42,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getPartitionerClass:()Ljava/lang/Class;
       9: areturn

  public boolean getProfileEnabled();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #43,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getProfileEnabled:()Z
       9: ireturn

  public java.lang.String getProfileParams();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #44,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getProfileParams:()Ljava/lang/String;
       9: areturn

  public org.apache.hadoop.conf.Configuration$IntegerRanges getProfileTaskRange(boolean);
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: iload_1
       5: invokeinterface #45,  2           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getProfileTaskRange:(Z)Lorg/apache/hadoop/conf/Configuration$IntegerRanges;
      10: areturn

  public java.lang.Class<? extends org.apache.hadoop.mapreduce.Reducer<?, ?, ?, ?>> getReducerClass() throws java.lang.ClassNotFoundException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #46,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getReducerClass:()Ljava/lang/Class;
       9: areturn

  public org.apache.hadoop.io.RawComparator<?> getSortComparator();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #47,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getSortComparator:()Lorg/apache/hadoop/io/RawComparator;
       9: areturn

  public boolean getSymlink();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #48,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getSymlink:()Z
       9: ireturn

  public java.lang.String getUser();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #49,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getUser:()Ljava/lang/String;
       9: areturn

  public org.apache.hadoop.fs.Path getWorkingDirectory() throws java.io.IOException;
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #50,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getWorkingDirectory:()Lorg/apache/hadoop/fs/Path;
       9: areturn

  public void progress();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #51,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.progress:()V
       9: return

  public org.apache.hadoop.security.Credentials getCredentials();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #52,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCredentials:()Lorg/apache/hadoop/security/Credentials;
       9: areturn

  public float getProgress();
    Code:
       0: aload_0
       1: getfield      #4                  // Field base:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       4: invokeinterface #53,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getProgress:()F
       9: freturn
}
