Compiled from "JobSplitWriter.java"
public class org.apache.hadoop.mapreduce.split.JobSplitWriter {
  private static final org.slf4j.Logger LOG;

  private static final int splitVersion;

  private static final byte[] SPLIT_FILE_HEADER;

  public org.apache.hadoop.mapreduce.split.JobSplitWriter();
    Code:
       0: aload_0
       1: invokespecial #2                  // Method java/lang/Object."<init>":()V
       4: return

  public static <T extends org.apache.hadoop.mapreduce.InputSplit> void createSplitFiles(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, java.util.List<org.apache.hadoop.mapreduce.InputSplit>) throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_3
       1: aload_3
       2: invokeinterface #3,  1            // InterfaceMethod java/util/List.size:()I
       7: anewarray     #4                  // class org/apache/hadoop/mapreduce/InputSplit
      10: invokeinterface #5,  2            // InterfaceMethod java/util/List.toArray:([Ljava/lang/Object;)[Ljava/lang/Object;
      15: checkcast     #6                  // class "[Lorg/apache/hadoop/mapreduce/InputSplit;"
      18: checkcast     #6                  // class "[Lorg/apache/hadoop/mapreduce/InputSplit;"
      21: astore        4
      23: aload_0
      24: aload_1
      25: aload_2
      26: aload         4
      28: invokestatic  #7                  // Method createSplitFiles:(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/FileSystem;[Lorg/apache/hadoop/mapreduce/InputSplit;)V
      31: return

  public static <T extends org.apache.hadoop.mapreduce.InputSplit> void createSplitFiles(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, T[]) throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_2
       1: aload_0
       2: invokestatic  #8                  // Method org/apache/hadoop/mapreduce/JobSubmissionFiles.getJobSplitFile:(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path;
       5: aload_1
       6: invokestatic  #9                  // Method createFile:(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/fs/FSDataOutputStream;
       9: astore        4
      11: aload_1
      12: aload_3
      13: aload         4
      15: invokestatic  #10                 // Method writeNewSplits:(Lorg/apache/hadoop/conf/Configuration;[Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/fs/FSDataOutputStream;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo;
      18: astore        5
      20: aload         4
      22: invokevirtual #11                 // Method org/apache/hadoop/fs/FSDataOutputStream.close:()V
      25: aload_2
      26: aload_0
      27: invokestatic  #12                 // Method org/apache/hadoop/mapreduce/JobSubmissionFiles.getJobSplitMetaFile:(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path;
      30: new           #13                 // class org/apache/hadoop/fs/permission/FsPermission
      33: dup
      34: getstatic     #14                 // Field org/apache/hadoop/mapreduce/JobSubmissionFiles.JOB_FILE_PERMISSION:Lorg/apache/hadoop/fs/permission/FsPermission;
      37: invokespecial #15                 // Method org/apache/hadoop/fs/permission/FsPermission."<init>":(Lorg/apache/hadoop/fs/permission/FsPermission;)V
      40: iconst_1
      41: aload         5
      43: invokestatic  #17                 // Method writeJobSplitMetaInfo:(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/permission/FsPermission;I[Lorg/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo;)V
      46: return

  public static void createSplitFiles(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, org.apache.hadoop.mapred.InputSplit[]) throws java.io.IOException;
    Code:
       0: aload_2
       1: aload_0
       2: invokestatic  #8                  // Method org/apache/hadoop/mapreduce/JobSubmissionFiles.getJobSplitFile:(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path;
       5: aload_1
       6: invokestatic  #9                  // Method createFile:(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/fs/FSDataOutputStream;
       9: astore        4
      11: aload_3
      12: aload         4
      14: aload_1
      15: invokestatic  #18                 // Method writeOldSplits:([Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/fs/FSDataOutputStream;Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo;
      18: astore        5
      20: aload         4
      22: invokevirtual #11                 // Method org/apache/hadoop/fs/FSDataOutputStream.close:()V
      25: aload_2
      26: aload_0
      27: invokestatic  #12                 // Method org/apache/hadoop/mapreduce/JobSubmissionFiles.getJobSplitMetaFile:(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path;
      30: new           #13                 // class org/apache/hadoop/fs/permission/FsPermission
      33: dup
      34: getstatic     #14                 // Field org/apache/hadoop/mapreduce/JobSubmissionFiles.JOB_FILE_PERMISSION:Lorg/apache/hadoop/fs/permission/FsPermission;
      37: invokespecial #15                 // Method org/apache/hadoop/fs/permission/FsPermission."<init>":(Lorg/apache/hadoop/fs/permission/FsPermission;)V
      40: iconst_1
      41: aload         5
      43: invokestatic  #17                 // Method writeJobSplitMetaInfo:(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/permission/FsPermission;I[Lorg/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo;)V
      46: return

  private static org.apache.hadoop.fs.FSDataOutputStream createFile(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration) throws java.io.IOException;
    Code:
       0: aload_0
       1: aload_1
       2: new           #13                 // class org/apache/hadoop/fs/permission/FsPermission
       5: dup
       6: getstatic     #14                 // Field org/apache/hadoop/mapreduce/JobSubmissionFiles.JOB_FILE_PERMISSION:Lorg/apache/hadoop/fs/permission/FsPermission;
       9: invokespecial #15                 // Method org/apache/hadoop/fs/permission/FsPermission."<init>":(Lorg/apache/hadoop/fs/permission/FsPermission;)V
      12: invokestatic  #19                 // Method org/apache/hadoop/fs/FileSystem.create:(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/permission/FsPermission;)Lorg/apache/hadoop/fs/FSDataOutputStream;
      15: astore_3
      16: aload_2
      17: ldc           #21                 // String mapreduce.client.submit.file.replication
      19: bipush        10
      21: invokevirtual #22                 // Method org/apache/hadoop/conf/Configuration.getInt:(Ljava/lang/String;I)I
      24: istore        4
      26: aload_0
      27: aload_1
      28: iload         4
      30: i2s
      31: invokevirtual #23                 // Method org/apache/hadoop/fs/FileSystem.setReplication:(Lorg/apache/hadoop/fs/Path;S)Z
      34: pop
      35: aload_3
      36: invokestatic  #24                 // Method writeSplitHeader:(Lorg/apache/hadoop/fs/FSDataOutputStream;)V
      39: aload_3
      40: areturn

  private static void writeSplitHeader(org.apache.hadoop.fs.FSDataOutputStream) throws java.io.IOException;
    Code:
       0: aload_0
       1: getstatic     #25                 // Field SPLIT_FILE_HEADER:[B
       4: invokevirtual #26                 // Method org/apache/hadoop/fs/FSDataOutputStream.write:([B)V
       7: aload_0
       8: iconst_1
       9: invokevirtual #27                 // Method org/apache/hadoop/fs/FSDataOutputStream.writeInt:(I)V
      12: return

  private static <T extends org.apache.hadoop.mapreduce.InputSplit> org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo[] writeNewSplits(org.apache.hadoop.conf.Configuration, T[], org.apache.hadoop.fs.FSDataOutputStream) throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_1
       1: arraylength
       2: anewarray     #28                 // class org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo
       5: astore_3
       6: aload_1
       7: arraylength
       8: ifeq          234
      11: new           #29                 // class org/apache/hadoop/io/serializer/SerializationFactory
      14: dup
      15: aload_0
      16: invokespecial #30                 // Method org/apache/hadoop/io/serializer/SerializationFactory."<init>":(Lorg/apache/hadoop/conf/Configuration;)V
      19: astore        4
      21: iconst_0
      22: istore        5
      24: aload_0
      25: ldc           #32                 // String mapreduce.job.max.split.locations
      27: bipush        15
      29: invokevirtual #22                 // Method org/apache/hadoop/conf/Configuration.getInt:(Ljava/lang/String;I)I
      32: istore        6
      34: aload_2
      35: invokevirtual #33                 // Method org/apache/hadoop/fs/FSDataOutputStream.getPos:()J
      38: lstore        7
      40: aload_1
      41: astore        9
      43: aload         9
      45: arraylength
      46: istore        10
      48: iconst_0
      49: istore        11
      51: iload         11
      53: iload         10
      55: if_icmpge     234
      58: aload         9
      60: iload         11
      62: aaload
      63: astore        12
      65: aload_2
      66: invokevirtual #33                 // Method org/apache/hadoop/fs/FSDataOutputStream.getPos:()J
      69: lstore        13
      71: aload_2
      72: aload         12
      74: invokevirtual #34                 // Method java/lang/Object.getClass:()Ljava/lang/Class;
      77: invokevirtual #35                 // Method java/lang/Class.getName:()Ljava/lang/String;
      80: invokestatic  #36                 // Method org/apache/hadoop/io/Text.writeString:(Ljava/io/DataOutput;Ljava/lang/String;)I
      83: pop
      84: aload         4
      86: aload         12
      88: invokevirtual #34                 // Method java/lang/Object.getClass:()Ljava/lang/Class;
      91: invokevirtual #37                 // Method org/apache/hadoop/io/serializer/SerializationFactory.getSerializer:(Ljava/lang/Class;)Lorg/apache/hadoop/io/serializer/Serializer;
      94: astore        15
      96: aload         15
      98: aload_2
      99: invokeinterface #38,  2           // InterfaceMethod org/apache/hadoop/io/serializer/Serializer.open:(Ljava/io/OutputStream;)V
     104: aload         15
     106: aload         12
     108: invokeinterface #39,  2           // InterfaceMethod org/apache/hadoop/io/serializer/Serializer.serialize:(Ljava/lang/Object;)V
     113: aload_2
     114: invokevirtual #33                 // Method org/apache/hadoop/fs/FSDataOutputStream.getPos:()J
     117: lstore        16
     119: aload         12
     121: invokevirtual #40                 // Method org/apache/hadoop/mapreduce/InputSplit.getLocations:()[Ljava/lang/String;
     124: astore        18
     126: aload         18
     128: arraylength
     129: iload         6
     131: if_icmple     195
     134: getstatic     #41                 // Field LOG:Lorg/slf4j/Logger;
     137: new           #42                 // class java/lang/StringBuilder
     140: dup
     141: invokespecial #43                 // Method java/lang/StringBuilder."<init>":()V
     144: ldc           #44                 // String Max block location exceeded for split:
     146: invokevirtual #45                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
     149: aload         12
     151: invokevirtual #46                 // Method java/lang/StringBuilder.append:(Ljava/lang/Object;)Ljava/lang/StringBuilder;
     154: ldc           #47                 // String  splitsize:
     156: invokevirtual #45                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
     159: aload         18
     161: arraylength
     162: invokevirtual #48                 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;
     165: ldc           #49                 // String  maxsize:
     167: invokevirtual #45                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
     170: iload         6
     172: invokevirtual #48                 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;
     175: invokevirtual #50                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;
     178: invokeinterface #51,  2           // InterfaceMethod org/slf4j/Logger.warn:(Ljava/lang/String;)V
     183: aload         18
     185: iload         6
     187: invokestatic  #52                 // Method java/util/Arrays.copyOf:([Ljava/lang/Object;I)[Ljava/lang/Object;
     190: checkcast     #53                 // class "[Ljava/lang/String;"
     193: astore        18
     195: aload_3
     196: iload         5
     198: iinc          5, 1
     201: new           #28                 // class org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo
     204: dup
     205: aload         18
     207: lload         7
     209: aload         12
     211: invokevirtual #54                 // Method org/apache/hadoop/mapreduce/InputSplit.getLength:()J
     214: invokespecial #55                 // Method org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo."<init>":([Ljava/lang/String;JJ)V
     217: aastore
     218: lload         7
     220: lload         16
     222: lload         13
     224: lsub
     225: ladd
     226: lstore        7
     228: iinc          11, 1
     231: goto          51
     234: aload_3
     235: areturn

  private static org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo[] writeOldSplits(org.apache.hadoop.mapred.InputSplit[], org.apache.hadoop.fs.FSDataOutputStream, org.apache.hadoop.conf.Configuration) throws java.io.IOException;
    Code:
       0: aload_0
       1: arraylength
       2: anewarray     #28                 // class org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo
       5: astore_3
       6: aload_0
       7: arraylength
       8: ifeq          207
      11: iconst_0
      12: istore        4
      14: aload_1
      15: invokevirtual #33                 // Method org/apache/hadoop/fs/FSDataOutputStream.getPos:()J
      18: lstore        5
      20: aload_2
      21: ldc           #32                 // String mapreduce.job.max.split.locations
      23: bipush        15
      25: invokevirtual #22                 // Method org/apache/hadoop/conf/Configuration.getInt:(Ljava/lang/String;I)I
      28: istore        7
      30: aload_0
      31: astore        8
      33: aload         8
      35: arraylength
      36: istore        9
      38: iconst_0
      39: istore        10
      41: iload         10
      43: iload         9
      45: if_icmpge     207
      48: aload         8
      50: iload         10
      52: aaload
      53: astore        11
      55: aload_1
      56: invokevirtual #33                 // Method org/apache/hadoop/fs/FSDataOutputStream.getPos:()J
      59: lstore        12
      61: aload_1
      62: aload         11
      64: invokevirtual #34                 // Method java/lang/Object.getClass:()Ljava/lang/Class;
      67: invokevirtual #35                 // Method java/lang/Class.getName:()Ljava/lang/String;
      70: invokestatic  #36                 // Method org/apache/hadoop/io/Text.writeString:(Ljava/io/DataOutput;Ljava/lang/String;)I
      73: pop
      74: aload         11
      76: aload_1
      77: invokeinterface #56,  2           // InterfaceMethod org/apache/hadoop/mapred/InputSplit.write:(Ljava/io/DataOutput;)V
      82: aload_1
      83: invokevirtual #33                 // Method org/apache/hadoop/fs/FSDataOutputStream.getPos:()J
      86: lstore        14
      88: aload         11
      90: invokeinterface #57,  1           // InterfaceMethod org/apache/hadoop/mapred/InputSplit.getLocations:()[Ljava/lang/String;
      95: astore        16
      97: aload         16
      99: arraylength
     100: iload         7
     102: if_icmple     166
     105: getstatic     #41                 // Field LOG:Lorg/slf4j/Logger;
     108: new           #42                 // class java/lang/StringBuilder
     111: dup
     112: invokespecial #43                 // Method java/lang/StringBuilder."<init>":()V
     115: ldc           #44                 // String Max block location exceeded for split:
     117: invokevirtual #45                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
     120: aload         11
     122: invokevirtual #46                 // Method java/lang/StringBuilder.append:(Ljava/lang/Object;)Ljava/lang/StringBuilder;
     125: ldc           #47                 // String  splitsize:
     127: invokevirtual #45                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
     130: aload         16
     132: arraylength
     133: invokevirtual #48                 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;
     136: ldc           #49                 // String  maxsize:
     138: invokevirtual #45                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
     141: iload         7
     143: invokevirtual #48                 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;
     146: invokevirtual #50                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;
     149: invokeinterface #51,  2           // InterfaceMethod org/slf4j/Logger.warn:(Ljava/lang/String;)V
     154: aload         16
     156: iload         7
     158: invokestatic  #52                 // Method java/util/Arrays.copyOf:([Ljava/lang/Object;I)[Ljava/lang/Object;
     161: checkcast     #53                 // class "[Ljava/lang/String;"
     164: astore        16
     166: aload_3
     167: iload         4
     169: iinc          4, 1
     172: new           #28                 // class org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo
     175: dup
     176: aload         16
     178: lload         5
     180: aload         11
     182: invokeinterface #58,  1           // InterfaceMethod org/apache/hadoop/mapred/InputSplit.getLength:()J
     187: invokespecial #55                 // Method org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo."<init>":([Ljava/lang/String;JJ)V
     190: aastore
     191: lload         5
     193: lload         14
     195: lload         12
     197: lsub
     198: ladd
     199: lstore        5
     201: iinc          10, 1
     204: goto          41
     207: aload_3
     208: areturn

  private static void writeJobSplitMetaInfo(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, int, org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo[]) throws java.io.IOException;
    Code:
       0: aload_0
       1: aload_1
       2: aload_2
       3: invokestatic  #19                 // Method org/apache/hadoop/fs/FileSystem.create:(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/permission/FsPermission;)Lorg/apache/hadoop/fs/FSDataOutputStream;
       6: astore        5
       8: aload         5
      10: getstatic     #59                 // Field org/apache/hadoop/mapreduce/split/JobSplit.META_SPLIT_FILE_HEADER:[B
      13: invokevirtual #26                 // Method org/apache/hadoop/fs/FSDataOutputStream.write:([B)V
      16: aload         5
      18: iload_3
      19: invokestatic  #60                 // Method org/apache/hadoop/io/WritableUtils.writeVInt:(Ljava/io/DataOutput;I)V
      22: aload         5
      24: aload         4
      26: arraylength
      27: invokestatic  #60                 // Method org/apache/hadoop/io/WritableUtils.writeVInt:(Ljava/io/DataOutput;I)V
      30: aload         4
      32: astore        6
      34: aload         6
      36: arraylength
      37: istore        7
      39: iconst_0
      40: istore        8
      42: iload         8
      44: iload         7
      46: if_icmpge     69
      49: aload         6
      51: iload         8
      53: aaload
      54: astore        9
      56: aload         9
      58: aload         5
      60: invokevirtual #61                 // Method org/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo.write:(Ljava/io/DataOutput;)V
      63: iinc          8, 1
      66: goto          42
      69: aload         5
      71: invokevirtual #11                 // Method org/apache/hadoop/fs/FSDataOutputStream.close:()V
      74: return

  static {};
    Code:
       0: ldc           #16                 // class org/apache/hadoop/mapreduce/split/JobSplitWriter
       2: invokestatic  #62                 // Method org/slf4j/LoggerFactory.getLogger:(Ljava/lang/Class;)Lorg/slf4j/Logger;
       5: putstatic     #41                 // Field LOG:Lorg/slf4j/Logger;
       8: ldc           #63                 // String SPL
      10: ldc           #64                 // String UTF-8
      12: invokevirtual #65                 // Method java/lang/String.getBytes:(Ljava/lang/String;)[B
      15: putstatic     #25                 // Field SPLIT_FILE_HEADER:[B
      18: goto          31
      21: astore_0
      22: new           #67                 // class java/lang/RuntimeException
      25: dup
      26: aload_0
      27: invokespecial #68                 // Method java/lang/RuntimeException."<init>":(Ljava/lang/Throwable;)V
      30: athrow
      31: return
    Exception table:
       from    to  target type
           8    18    21   Class java/io/UnsupportedEncodingException
}
