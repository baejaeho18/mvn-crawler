Compiled from "Chain.java"
class org.apache.hadoop.mapreduce.lib.chain.Chain$ChainRecordReader<KEYIN, VALUEIN> extends org.apache.hadoop.mapreduce.RecordReader<KEYIN, VALUEIN> {
  private java.lang.Class<?> keyClass;

  private java.lang.Class<?> valueClass;

  private KEYIN key;

  private VALUEIN value;

  private org.apache.hadoop.conf.Configuration conf;

  org.apache.hadoop.mapreduce.TaskInputOutputContext<KEYIN, VALUEIN, ?, ?> inputContext;

  org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue<org.apache.hadoop.mapreduce.lib.chain.Chain$KeyValuePair<KEYIN, VALUEIN>> inputQueue;

  org.apache.hadoop.mapreduce.lib.chain.Chain$ChainRecordReader(java.lang.Class<?>, java.lang.Class<?>, org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue<org.apache.hadoop.mapreduce.lib.chain.Chain$KeyValuePair<KEYIN, VALUEIN>>, org.apache.hadoop.conf.Configuration);
    Code:
       0: aload_0
       1: invokespecial #1                  // Method org/apache/hadoop/mapreduce/RecordReader."<init>":()V
       4: aload_0
       5: aconst_null
       6: putfield      #2                  // Field inputContext:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       9: aload_0
      10: aconst_null
      11: putfield      #3                  // Field inputQueue:Lorg/apache/hadoop/mapreduce/lib/chain/Chain$ChainBlockingQueue;
      14: aload_0
      15: aload_1
      16: putfield      #4                  // Field keyClass:Ljava/lang/Class;
      19: aload_0
      20: aload_2
      21: putfield      #5                  // Field valueClass:Ljava/lang/Class;
      24: aload_0
      25: aload_3
      26: putfield      #3                  // Field inputQueue:Lorg/apache/hadoop/mapreduce/lib/chain/Chain$ChainBlockingQueue;
      29: aload_0
      30: aload         4
      32: putfield      #6                  // Field conf:Lorg/apache/hadoop/conf/Configuration;
      35: return

  org.apache.hadoop.mapreduce.lib.chain.Chain$ChainRecordReader(org.apache.hadoop.mapreduce.TaskInputOutputContext<KEYIN, VALUEIN, ?, ?>);
    Code:
       0: aload_0
       1: invokespecial #1                  // Method org/apache/hadoop/mapreduce/RecordReader."<init>":()V
       4: aload_0
       5: aconst_null
       6: putfield      #2                  // Field inputContext:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
       9: aload_0
      10: aconst_null
      11: putfield      #3                  // Field inputQueue:Lorg/apache/hadoop/mapreduce/lib/chain/Chain$ChainBlockingQueue;
      14: aload_0
      15: aload_1
      16: putfield      #2                  // Field inputContext:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
      19: return

  public void initialize(org.apache.hadoop.mapreduce.InputSplit, org.apache.hadoop.mapreduce.TaskAttemptContext) throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: return

  public boolean nextKeyValue() throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_0
       1: getfield      #3                  // Field inputQueue:Lorg/apache/hadoop/mapreduce/lib/chain/Chain$ChainBlockingQueue;
       4: ifnull        12
       7: aload_0
       8: invokespecial #7                  // Method readFromQueue:()Z
      11: ireturn
      12: aload_0
      13: getfield      #2                  // Field inputContext:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
      16: invokeinterface #8,  1            // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.nextKeyValue:()Z
      21: ifeq          52
      24: aload_0
      25: aload_0
      26: getfield      #2                  // Field inputContext:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
      29: invokeinterface #9,  1            // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCurrentKey:()Ljava/lang/Object;
      34: putfield      #10                 // Field key:Ljava/lang/Object;
      37: aload_0
      38: aload_0
      39: getfield      #2                  // Field inputContext:Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;
      42: invokeinterface #11,  1           // InterfaceMethod org/apache/hadoop/mapreduce/TaskInputOutputContext.getCurrentValue:()Ljava/lang/Object;
      47: putfield      #12                 // Field value:Ljava/lang/Object;
      50: iconst_1
      51: ireturn
      52: iconst_0
      53: ireturn

  private boolean readFromQueue() throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aconst_null
       1: astore_1
       2: aload_0
       3: getfield      #3                  // Field inputQueue:Lorg/apache/hadoop/mapreduce/lib/chain/Chain$ChainBlockingQueue;
       6: invokevirtual #13                 // Method org/apache/hadoop/mapreduce/lib/chain/Chain$ChainBlockingQueue.dequeue:()Ljava/lang/Object;
       9: checkcast     #14                 // class org/apache/hadoop/mapreduce/lib/chain/Chain$KeyValuePair
      12: astore_1
      13: aload_1
      14: getfield      #15                 // Field org/apache/hadoop/mapreduce/lib/chain/Chain$KeyValuePair.endOfInput:Z
      17: ifeq          22
      20: iconst_0
      21: ireturn
      22: aload_0
      23: aload_0
      24: getfield      #4                  // Field keyClass:Ljava/lang/Class;
      27: aload_0
      28: getfield      #6                  // Field conf:Lorg/apache/hadoop/conf/Configuration;
      31: invokestatic  #16                 // Method org/apache/hadoop/util/ReflectionUtils.newInstance:(Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;)Ljava/lang/Object;
      34: putfield      #10                 // Field key:Ljava/lang/Object;
      37: aload_0
      38: aload_0
      39: getfield      #5                  // Field valueClass:Ljava/lang/Class;
      42: aload_0
      43: getfield      #6                  // Field conf:Lorg/apache/hadoop/conf/Configuration;
      46: invokestatic  #16                 // Method org/apache/hadoop/util/ReflectionUtils.newInstance:(Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;)Ljava/lang/Object;
      49: putfield      #12                 // Field value:Ljava/lang/Object;
      52: aload_0
      53: getfield      #6                  // Field conf:Lorg/apache/hadoop/conf/Configuration;
      56: aload_1
      57: getfield      #17                 // Field org/apache/hadoop/mapreduce/lib/chain/Chain$KeyValuePair.key:Ljava/lang/Object;
      60: aload_0
      61: getfield      #10                 // Field key:Ljava/lang/Object;
      64: invokestatic  #18                 // Method org/apache/hadoop/util/ReflectionUtils.copy:(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;
      67: pop
      68: aload_0
      69: getfield      #6                  // Field conf:Lorg/apache/hadoop/conf/Configuration;
      72: aload_1
      73: getfield      #19                 // Field org/apache/hadoop/mapreduce/lib/chain/Chain$KeyValuePair.value:Ljava/lang/Object;
      76: aload_0
      77: getfield      #12                 // Field value:Ljava/lang/Object;
      80: invokestatic  #18                 // Method org/apache/hadoop/util/ReflectionUtils.copy:(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;
      83: pop
      84: iconst_1
      85: ireturn

  public KEYIN getCurrentKey() throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_0
       1: getfield      #10                 // Field key:Ljava/lang/Object;
       4: areturn

  public VALUEIN getCurrentValue() throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: aload_0
       1: getfield      #12                 // Field value:Ljava/lang/Object;
       4: areturn

  public void close() throws java.io.IOException;
    Code:
       0: return

  public float getProgress() throws java.io.IOException, java.lang.InterruptedException;
    Code:
       0: fconst_0
       1: freturn
}
