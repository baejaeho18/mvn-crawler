

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Sparkling Water Configuration Properties &mdash; H2O Sparkling Water 3.36.1.4-1-3.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/contentui.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/contentui.css" type="text/css" />
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Memory Allocation" href="memory_setup.html" />
    <link rel="prev" title="Configuration" href="configuration.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                3.36.1.4-1-3.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about.html">About Sparkling Water</a></li>
<li class="toctree-l1"><a class="reference internal" href="../typical_use_case.html">Typical Use Case</a></li>
<li class="toctree-l1"><a class="reference internal" href="../requirements.html">Sparkling Water Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/install_and_start.html">Installing and Starting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/design.html">Design</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="configuration.html">Configuration</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Sparkling Water Configuration Properties</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#configuration-properties-independent-of-selected-backend">Configuration properties independent of selected backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="#internal-backend-configuration-properties">Internal backend configuration properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#external-backend-configuration-properties">External backend configuration properties</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="memory_setup.html">Memory Allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal_backend_tuning.html">Sparkling Water Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="enforce_system_level_properties.html">Enforce System-Level Command Line Arguments in External Backend on YARN</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/deployment.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml/ml.html">Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics/metrics.html">Metric Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_details/model_details.html">Model Details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parameters/parameters.html">Algorithm Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tutorials.html">How to…</a></li>
<li class="toctree-l1"><a class="reference internal" href="../devel/devel.html">Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pysparkling.html">PySparkling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rsparkling.html">RSparkling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide.html">Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOG.html">Change Log</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">H2O Sparkling Water</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="configuration.html">Configuration</a> &raquo;</li>
        
      <li>Sparkling Water Configuration Properties</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/configuration/configuration_properties.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="sparkling-water-configuration-properties">
<span id="sw-config-properties"></span><h1>Sparkling Water Configuration Properties<a class="headerlink" href="#sparkling-water-configuration-properties" title="Permalink to this headline">¶</a></h1>
<p>The following configuration properties can be passed to Spark to configure Sparking Water.</p>
<div class="section" id="configuration-properties-independent-of-selected-backend">
<h2>Configuration properties independent of selected backend<a class="headerlink" href="#configuration-properties-independent-of-selected-backend" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 19%" />
<col style="width: 5%" />
<col style="width: 24%" />
<col style="width: 52%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Default value</p></th>
<th class="head"><p>H2OConf setter (* <a class="reference internal" href="#getter">getter</a>)</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.backend.cluster.mode</span></code></p></td>
<td><p>internal</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setInternalClusterMode()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setExternalClusterMode()</span></code></p>
</td>
<td><p>This option can be set either to <code class="docutils literal notranslate"><span class="pre">internal</span></code> or <code class="docutils literal notranslate"><span class="pre">external</span></code>. When set to <code class="docutils literal notranslate"><span class="pre">external</span></code>, <code class="docutils literal notranslate"><span class="pre">H2O</span> <span class="pre">Context</span></code> is
created by connecting to existing H2O cluster, otherwise H2O cluster located inside Spark is created. That
means that each Spark executor will have one H2O instance running in it. The <code class="docutils literal notranslate"><span class="pre">internal</span></code> mode is not
recommended for big clusters and clusters where Spark executors are not stable.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cloud.name</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setCloudName(String)</span></code></p></td>
<td><p>Name of H2O cluster. If this option is not set, the name is automatically generated</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.nthreads</span></code></p></td>
<td><p>-1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setNthreads(Integer)</span></code></p></td>
<td><p>Limit for number of threads used by H2O.
Default <code class="docutils literal notranslate"><span class="pre">-1</span></code> using internal backend means: Use the value of <code class="docutils literal notranslate"><span class="pre">spark.executor.cores</span></code> if the property is set,
otherwise use H2O’s default value Runtime.getRuntime().availableProcessors().
Default <code class="docutils literal notranslate"><span class="pre">-1</span></code> using automatically started external backend on Hadoop means:
Use H2O’s default value Runtime.getRuntime().availableProcessors()
Default <code class="docutils literal notranslate"><span class="pre">-1</span></code> using automatically started external backend on Kubernetes means: Use just one cpu.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.progressbar.enabled</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setProgressBarEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setProgressBarDisabled()</span></code></p>
</td>
<td><p>Decides whether to display progress bar related to H2O jobs on stdout or not.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.model.print.after.training.enabled</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setModelPrintAfterTrainingEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setModelPrintAfterTrainingDisabled()</span></code></p>
</td>
<td><p>Decides whether to display model info on stdout after training or not.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.repl.enabled</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setReplEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setReplDisabled()</span></code></p>
</td>
<td><p>Decides whether H2O REPL is initiated or not.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.scala.int.default.num</span></code></p></td>
<td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setDefaultNumReplSessions(Integer)</span></code></p></td>
<td><p>Number of parallel REPL sessions started at the start of Sparkling Water.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.topology.change.listener.enabled</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClusterTopologyListenerEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setClusterTopologyListenerDisabled()</span></code></p>
</td>
<td><p>Decides whether listener which kills H2O cluster on the change of the underlying cluster’s topology is
enabled or not. This configuration has effect only in non-local mode.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.spark.version.check.enabled</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setSparkVersionCheckEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setSparkVersionCheckDisabled()</span></code></p>
</td>
<td><p>Enables check if run-time Spark version matches build time Spark version.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.fail.on.unsupported.spark.param</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setFailOnUnsupportedSparkParamEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setFailOnUnsupportedSparkParamDisabled()</span></code></p>
</td>
<td><p>If unsupported Spark parameter is detected, then application is forced to shutdown.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.jks</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setJks(String)</span></code></p></td>
<td><p>Path to a Java keystore file with certificates securing H2O Flow UI and internal REST connections between
instances (driver + executors) and H2O nodes. When configuring this property, you must consider that a Spark executor
can communicate to any of H2O nodes and verifies H2O node according to the hostname specified in the keystore
certificate. You can consider usage of a wildcard certificate or you can disable the hostname verification
completely with the <code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.verify_ssl_hostnames</span></code> property.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.jks.pass</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setJksPass(String)</span></code></p></td>
<td><p>Password for the Java keystore file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.jks.alias</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setJksAlias(String)</span></code></p></td>
<td><p>Alias to certificate in the to the Java keystore file to secure H2O Flow UI and internal REST connections
between Spark instances (driver + executors) and H2O nodes.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.ssl.ca.cert</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setSslCACert(String)</span></code></p></td>
<td><p>A path to a CA bundle file or a directory with certificates of trusted CAs. This path is used by RSparkling or
PySparking for connecting to a Sparkling Water backend.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.hash.login</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setHashLoginEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setHashLoginDisabled()</span></code></p>
</td>
<td><p>Enable hash login.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.ldap.login</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setLdapLoginEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setLdapLoginDisabled()</span></code></p>
</td>
<td><p>Enable LDAP login.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.kerberos.login</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setKerberosLoginEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setKerberosLoginDisabled()</span></code></p>
</td>
<td><p>Enable Kerberos login.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.login.conf</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setLoginConf(String)</span></code></p></td>
<td><p>Login configuration file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.user.name</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setUserName(String)</span></code></p></td>
<td><p>Username used for the backend H2O cluster and to authenticate the client against the backend.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.password</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setPassword(String)</span></code></p></td>
<td><p>Password used to authenticate the client against the backend.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.internal_security_conf</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setSslConf(String)</span></code></p></td>
<td><p>Path to a file containing H2O or Sparkling Water internal security configuration.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.auto.flow.ssl</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setAutoFlowSslEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setAutoFlowSslDisabled()</span></code></p>
</td>
<td><p>Automatically generate the required key store and password to secure secure H2O Flow UI and internal REST
connections between Spark executors and H2O nodes. Hostname verification is disabled when creating SSL
connections to H2O nodes.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.log.level</span></code></p></td>
<td><p>INFO</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setLogLevel(String)</span></code></p></td>
<td><p>H2O log level.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.log.dir</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setLogDir(String)</span></code></p></td>
<td><p>Location of H2O logs. When not specified, it uses {user.dir}/h2ologs/{AppId} or YARN container dir</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.backend.heartbeat.interval</span></code></p></td>
<td><p>10000</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setBackendHeartbeatInterval(Integer)</span></code></p></td>
<td><p>Interval (in msec) for getting heartbeat from the H2O backend.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cloud.timeout</span></code></p></td>
<td><p>60000</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setCloudTimeout(Integer)</span></code></p></td>
<td><p>Timeout (in msec) for cluster formation.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.node.network.mask</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setNodeNetworkMask(String)</span></code></p></td>
<td><p>Subnet selector for H2O running inside park executors. This disables using IP reported by Spark but tries to
find IP based on the specified mask.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.stacktrace.collector.interval</span></code></p></td>
<td><p>-1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setStacktraceCollectorInterval(Integer)</span></code></p></td>
<td><p>Interval specifying how often stack traces are taken on each H2O node. -1 means
that no stack traces will be taken</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.context.path</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setContextPath(String)</span></code></p></td>
<td><p>Context path to expose H2O web server.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.flow.scala.cell.async</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setFlowScalaCellAsyncEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setFlowScalaCellAsyncDisabled()</span></code></p>
</td>
<td><p>Decide whether the Scala cells in H2O Flow will run synchronously or Asynchronously. Default is synchronously.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.flow.scala.cell.max.parallel</span></code></p></td>
<td><p>-1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setMaxParallelScalaCellJobs(Integer)</span></code></p></td>
<td><p>Number of max parallel Scala cell jobs. The value -1 means not limited.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.internal.port.offset</span></code></p></td>
<td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setInternalPortOffset(Integer)</span></code></p></td>
<td><p>Offset between the API(=web) port and the internal communication port on the client
node; <code class="docutils literal notranslate"><span class="pre">api_port</span> <span class="pre">+</span> <span class="pre">port_offset</span> <span class="pre">=</span> <span class="pre">h2o_port</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.base.port</span></code></p></td>
<td><p>54321</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setBasePort(Integer)</span></code></p></td>
<td><p>Base port used for individual H2O nodes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.mojo.destroy.timeout</span></code></p></td>
<td><p>600000</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setMojoDestroyTimeout(Integer)</span></code></p></td>
<td><p>If a scoring MOJO instance is not used within a Spark executor JVM for a given timeout in milliseconds, it’s
evicted from executor’s cache. Default timeout value is 10 minutes.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.extra.properties</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExtraProperties(String)</span></code></p></td>
<td><p>A string containing extra parameters passed to H2O nodes during startup. This parameter should be
configured only if H2O parameters do not have any corresponding parameters in Sparkling Water.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.flow.dir</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setFlowDir(String)</span></code></p></td>
<td><p>Directory where flows from H2O Flow are saved.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.flow.extra.http.headers</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setFlowExtraHttpHeaders(Map[String,String])</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setFlowExtraHttpHeaders(String)</span></code></p>
</td>
<td><p>Extra HTTP headers that will be used in communication between the front-end and back-end part of Flow UI. The
headers should be delimited by a new line. Don’t forget to escape special characters when passing
the parameter from a command line. Example: <code class="docutils literal notranslate"><span class="pre">&quot;spark.ext.h2o.flow.extra.http.headers=Strict-Transport-Security:max-age=31536000&quot;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.flow.proxy.request.maxSize</span></code></p></td>
<td><p>32768</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setFlowProxyRequestMaxSize(Integer)</span></code></p></td>
<td><p>The maximum size of a request coming to flow UI proxy running on the Spark driver. The request is forwarded to Flow UI on H2O leader node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.flow.proxy.response.maxSize</span></code></p></td>
<td><p>32768</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setFlowProxyResponseMaxSize(Integer)</span></code></p></td>
<td><p>The maximum size of a response coming from flow UI proxy running on the Spark driver. The content for the response comes from Flow UI H2O leader node.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.internal_secure_connections</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setInternalSecureConnectionsEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setInternalSecureConnectionsDisabled()</span></code></p>
</td>
<td><p>Enables secure communications among H2O nodes. The security is based on
automatically generated keystore and truststore. This is equivalent for
<code class="docutils literal notranslate"><span class="pre">-internal_secure_conections</span></code> option in H2O Hadoop. More information
is available in the H2O documentation.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.allow_insecure_xgboost</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setInsecureXGBoostAllowed()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setInsecureXGBoostDenied()</span></code></p>
</td>
<td><p>If the property set to true, insecure communication among H2O nodes is
allowed for the XGBoost algorithm even if the other security options are enabled</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.client.ip</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClientIp(String)</span></code></p></td>
<td><p>IP of H2O client node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.client.web.port</span></code></p></td>
<td><p>-1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClientWebPort(Integer)</span></code></p></td>
<td><p>Exact client port to access web UI. The value <code class="docutils literal notranslate"><span class="pre">-1</span></code> means automatic
search for a free port starting at <code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.base.port</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.client.verbose</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClientVerboseEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setClientVerboseDisabled()</span></code></p>
</td>
<td><p>The client outputs verbose log output directly into console. Enabling the
flag increases the client log level to <code class="docutils literal notranslate"><span class="pre">INFO</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.client.network.mask</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClientNetworkMask(String)</span></code></p></td>
<td><p>Subnet selector for H2O client, this disables using IP reported by Spark
but tries to find IP based on the specified mask.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.client.flow.baseurl.override</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClientFlowBaseurlOverride(String)</span></code></p></td>
<td><p>Allows to override the base URL address of Flow UI, including the
scheme, which is showed to the user.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cluster.client.retry.timeout</span></code></p></td>
<td><p>60000</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClientCheckRetryTimeout(Integer)</span></code></p></td>
<td><p>Timeout in milliseconds specifying how often we check whether the
the client is still connected.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.verify_ssl_certificates</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setVerifySslCertificates(Boolean)</span></code></p></td>
<td><p>If the property is enabled, Pysparkling or RSparkling client will verify certificates when connecting
Sparkling Water Flow UI.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.internal.rest.verify_ssl_certificates</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setSslCertificateVerificationInInternalRestConnectionsEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setSslCertificateVerificationInInternalRestConnectionsDisabled()</span></code></p>
</td>
<td><p>If the property is enabled, Sparkling Water will verify ssl certificates during establishing secured http connections
to one of H2O nodes. Such connections are utilized for delegation of Flow UI calls to H2O leader node or
during data exchange between Spark executors and H2O nodes. If the property is disabled, hostname verification is
disabled as well.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.internal.rest.verify_ssl_hostnames</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setSslHostnameVerificationInInternalRestConnectionsEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setSslHostnameVerificationInInternalRestConnectionsDisabled()</span></code></p>
</td>
<td><p>If the property is enabled, Sparkling Water will verify a hostname during establishing of secured http connections
to one of H2O nodes. Such connections are utilized for delegation of Flow UI calls to H2O leader node or
during data exchange between Spark executors and H2O nodes.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.kerberized.hive.enabled</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setKerberizedHiveEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setKerberizedHiveDisabled()</span></code></p>
</td>
<td><p>If enabled, H2O instances will create  JDBC connections to a Kerberized Hive
so that all clients can read data from HiveServer2. Don’t forget to put
a jar with Hive driver on Spark classpath if the internal backend is used.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.hive.host</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setHiveHost(String)</span></code></p></td>
<td><p>The full address of HiveServer2, for example hostname:10000.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.hive.principal</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setHivePrincipal(String)</span></code></p></td>
<td><p>Hiveserver2 Kerberos principal, for example <a class="reference external" href="mailto:hive/hostname&#37;&#52;&#48;DOMAIN&#46;COM">hive/hostname<span>&#64;</span>DOMAIN<span>&#46;</span>COM</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.hive.jdbc_url_pattern</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setHiveJdbcUrlPattern(String)</span></code></p></td>
<td><p>A pattern of JDBC URL used for connecting to Hiveserver2. Example: <code class="docutils literal notranslate"><span class="pre">jdbc:hive2://{{host}}/;{{auth}}</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.hive.token</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setHiveToken(String)</span></code></p></td>
<td><p>An authorization token to Hive.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.iced.dir</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setIcedDir(String)</span></code></p></td>
<td><p>Location of iced directory for H2O nodes.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.rest.api.timeout</span></code></p></td>
<td><p>300000</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setSessionTimeout(Boolean)</span></code></p></td>
<td><p>Timeout in milliseconds for Rest API requests.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<div class="section" id="internal-backend-configuration-properties">
<h2>Internal backend configuration properties<a class="headerlink" href="#internal-backend-configuration-properties" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 21%" />
<col style="width: 7%" />
<col style="width: 19%" />
<col style="width: 53%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Default value</p></th>
<th class="head"><p>H2OConf setter (* <a class="reference internal" href="#getter">getter</a>)</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cluster.size</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setNumH2OWorkers(Integer)</span></code></p></td>
<td><p>Expected number of workers of H2O cluster. Value None means automatic
detection of cluster size. This number must be equal to number of Spark executors. If Spark property
<code class="docutils literal notranslate"><span class="pre">spark.executor.instances</span></code> is specified, this Sparkling Water property is set to its value.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.extra.cluster.nodes</span></code></p></td>
<td><p>false</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExtraClusterNodesEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setExtraClusterNodesDisabled()</span></code></p>
</td>
<td><p>If the property is set true and the Sparkling Water internal backend identifies more executors than specified in
the Spark property  <code class="docutils literal notranslate"><span class="pre">spark.executor.instances</span></code> or in  the Sparkling Water property
<code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cluster.size</span></code>, Sparkling Water deploys H2O nodes to all discovered Spark executors. Otherwise,
Sparkling Water deploys just a number of executors specified in  <code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cluster.size</span></code>
(or <code class="docutils literal notranslate"><span class="pre">spark.executor.instances</span></code>).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.dummy.rdd.mul.factor</span></code></p></td>
<td><p>10</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setDrddMulFactor(Integer)</span></code></p></td>
<td><p>Multiplication factor for dummy RDD  generation. Size of dummy RDD is
<code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cluster.size</span></code> multiplied by this option.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.spreadrdd.retries</span></code></p></td>
<td><p>10</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setNumRddRetries(Integer)</span></code></p></td>
<td><p>Number of retries for creation of an RDD spread across all existing Spark executors</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.default.cluster.size</span></code></p></td>
<td><p>20</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setDefaultCloudSize(Integer)</span></code></p></td>
<td><p>Starting size of cluster in case that size is not explicitly configured.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.subseq.tries</span></code></p></td>
<td><p>5</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setSubseqTries(Integer)</span></code></p></td>
<td><p>Subsequent successful tries to figure out size of Spark cluster, which are
producing the same number of nodes.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.hdfs_conf</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setHdfsConf(String)</span></code></p></td>
<td><p>Either a string with the Path to a file with Hadoop HDFS configuration or the
hadoop.conf.Configuration object in the org.apache package. Useful for HDFS credentials
settings and other HDFS-related configurations. Default value None means
use <cite>sc.hadoopConfig</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.spreadrdd.retries.timeout</span></code></p></td>
<td><p>0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setSpreadRddRetriesTimeout(Int)</span></code></p></td>
<td><p>Specifies how long the discovering of Spark executors should last. This
option has precedence over other options influencing the discovery
mechanism. That means that as long as the timeout hasn’t expired, we keep
trying to discover new executors. This option might be useful in environments
where Spark executors might join the cloud with some delays.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.direct.configuration.ip</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setDirectIpConfigurationEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setDirectIpConfigurationDisabled()</span></code></p>
</td>
<td><p>If the property is disabled, Spark executor doesn’t assign its IP address to H2O node directly. The IP address is
suggested to H2O node and its bootstrap logic performs additional network interface availability checks before
the IP is assigned to the node.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<div class="section" id="external-backend-configuration-properties">
<h2>External backend configuration properties<a class="headerlink" href="#external-backend-configuration-properties" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 21%" />
<col style="width: 7%" />
<col style="width: 19%" />
<col style="width: 53%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Default value</p></th>
<th class="head"><p>H2OConf setter (* <a class="reference internal" href="#getter">getter</a>)</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.driver.if</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalH2ODriverIf(String)</span></code></p></td>
<td><p>Ip address or network of mapper-&gt;driver callback interface. Default value means automatic detection.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.driver.port</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalH2ODriverPort(Integer)</span></code></p></td>
<td><p>Port of mapper-&gt;driver callback interface. Default value means automatic detection.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.driver.port.range</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalH2ODriverPortRange(String)</span></code></p></td>
<td><p>Range portX-portY of mapper-&gt;driver callback interface; eg: 50000-55000.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.extra.memory.percent</span></code></p></td>
<td><p>10</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalExtraMemoryPercent(Integer)</span></code></p></td>
<td><p>This option is a percentage of external memory option and specifies memory
for internal JVM use outside of Java heap.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cloud.representative</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setH2OCluster(String)</span></code></p></td>
<td><p>ip:port of a H2O cluster leader node to identify external H2O cluster.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.cluster.size</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClusterSize(Integer)</span></code></p></td>
<td><p>Number of H2O nodes to start when <code class="docutils literal notranslate"><span class="pre">auto</span></code> mode of the external backend is set.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cluster.start.timeout</span></code></p></td>
<td><p>120</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClusterStartTimeout(Integer)</span></code></p></td>
<td><p>Timeout in seconds for starting H2O external cluster</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.cluster.info.name</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setClusterInfoFile(Integer)</span></code></p></td>
<td><p>Full path to a file which is used as the notification file for the startup of external H2O cluster.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.memory</span></code></p></td>
<td><p>6G</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalMemory(String)</span></code></p></td>
<td><p>Amount of memory assigned to each external H2O node</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.hdfs.dir</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setHDFSOutputDir(String)</span></code></p></td>
<td><p>Path to the directory on HDFS used for storing temporary files.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.start.mode</span></code></p></td>
<td><p>manual</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">useAutoClusterStart()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">useManualClusterStart()</span></code></p>
</td>
<td><p>If this option is set to <code class="docutils literal notranslate"><span class="pre">auto</span></code> then H2O external cluster is automatically started using the
provided H2O driver JAR on YARN, otherwise it is expected that the cluster is started by the user
manually</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.h2o.driver</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setH2ODriverPath(String)</span></code></p></td>
<td><p>Path to H2O driver used during <code class="docutils literal notranslate"><span class="pre">auto</span></code> start mode.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.yarn.queue</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setYARNQueue(String)</span></code></p></td>
<td><p>Yarn queue on which external H2O cluster is started.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.kill.on.unhealthy</span></code></p></td>
<td><p>true</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setKillOnUnhealthyClusterEnabled()</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setKillOnUnhealthyClusterDisabled()</span></code></p>
</td>
<td><p>If true, the client will try to kill the cluster and then itself in
case some nodes in the cluster report unhealthy status.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.kerberos.principal</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setKerberosPrincipal(String)</span></code></p></td>
<td><p>Kerberos Principal</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.kerberos.keytab</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setKerberosKeytab(String)</span></code></p></td>
<td><p>Kerberos Keytab</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.run.as.user</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setRunAsUser(String)</span></code></p></td>
<td><p>Impersonated Hadoop user</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.backend.stop.timeout</span></code></p></td>
<td><p>10000</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalBackendStopTimeout(Integer)</span></code></p></td>
<td><p>Timeout for confirmation from worker nodes when stopping the  external backend. It is also
possible to pass <code class="docutils literal notranslate"><span class="pre">-1</span></code> to ensure the indefinite timeout. The unit is milliseconds.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.hadoop.executable</span></code></p></td>
<td><p>hadoop</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalHadoopExecutable(String)</span></code></p></td>
<td><p>Name or path to path to a hadoop  executable binary which is used
to start external H2O backend on YARN.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.extra.jars</span></code></p></td>
<td><p>None</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalExtraJars(String)</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">setExternalExtraJars(String[])</span></code></p>
</td>
<td><p>Comma-separated paths to jars that will be placed onto classpath of each H2O node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.communication.compression</span></code></p></td>
<td><p>SNAPPY</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalCommunicationCompression(String)</span></code></p></td>
<td><p>The type of compression used for data transfer between Spark and H2O node.
Possible values are <code class="docutils literal notranslate"><span class="pre">NONE</span></code>, <code class="docutils literal notranslate"><span class="pre">DEFLATE</span></code>, <code class="docutils literal notranslate"><span class="pre">GZIP</span></code>, <code class="docutils literal notranslate"><span class="pre">SNAPPY</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.auto.start.backend</span></code></p></td>
<td><p>yarn</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalAutoStartBackend(String)</span></code></p></td>
<td><p>The backend on which the external H2O backend will be started in auto start mode.
Possible values are <code class="docutils literal notranslate"><span class="pre">YARN</span></code> and <code class="docutils literal notranslate"><span class="pre">KUBERNETES</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.k8s.h2o.service.name</span></code></p></td>
<td><p>h2o-service</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalK8sH2OServceName(String)</span></code></p></td>
<td><p>Name of H2O service required to start H2O on K8s.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.k8s.h2o.statefulset.name</span></code></p></td>
<td><p>h2o-statefulset</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalK8sH2OStatefulsetName(String)</span></code></p></td>
<td><p>Name of H2O stateful set required to start H2O on K8s.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.k8s.h2o.label</span></code></p></td>
<td><p>app=h2o</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalK8sH2OLabel(String)</span></code></p></td>
<td><p>Label used to select node for H2O cluster formation.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.k8s.h2o.api.port</span></code></p></td>
<td><p>8081</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalK8sH2OApiPort(String)</span></code></p></td>
<td><p>Kubernetes API port.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.k8s.namespace</span></code></p></td>
<td><p>default</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalK8sNamespace(String)</span></code></p></td>
<td><p>Kubernetes namespace where external H2O is started.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.k8s.docker.image</span></code></p></td>
<td><p>See doc</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalK8sDockerImage(String)</span></code></p></td>
<td><p>Docker image containing Sparkling Water external H2O backend. Default value is h2oai/sparkling-water-external-backend:3.36.1.4-1-3.1</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.k8s.domain</span></code></p></td>
<td><p>cluster.local</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalK8sDomain(String)</span></code></p></td>
<td><p>Domain of the Kubernetes cluster.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spark.ext.h2o.external.k8s.svc.timeout</span></code></p></td>
<td><p>300</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setExternalK8sServiceTimeout(Int)</span></code></p></td>
<td><p>[Deprecated] Timeout in seconds used as a limit for K8s service creation.</p></td>
</tr>
</tbody>
</table>
<hr class="docutils" />
<p id="getter">H2OConf getter can be derived from the corresponding setter. All getters are parameter-less. If the type of the property is Boolean, the getter is prefixed with
<code class="docutils literal notranslate"><span class="pre">is</span></code> (E.g. <code class="docutils literal notranslate"><span class="pre">setReplEnabled()</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">isReplEnabled()</span></code>). Property getters of other types do not have any prefix and start with lowercase
(E.g. <code class="docutils literal notranslate"><span class="pre">setUserName(String)</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">userName</span></code> for Scala, <code class="docutils literal notranslate"><span class="pre">userName()</span></code> for Python).</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="memory_setup.html" class="btn btn-neutral float-right" title="Memory Allocation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="configuration.html" class="btn btn-neutral float-left" title="Configuration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016-2020 H2O.ai
      <span class="lastupdated">
        Last updated on Aug 04, 2022.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>