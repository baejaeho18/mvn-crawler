Compiled from "Task.java"
public interface org.apache.kafka.streams.processor.internals.Task {
  public static final long LATEST_OFFSET;

  public abstract org.apache.kafka.streams.processor.TaskId id();

  public abstract org.apache.kafka.streams.processor.internals.Task$State state();

  public default boolean needsInitializationOrRestoration();
    Code:
       0: aload_0
       1: invokeinterface #1,  1            // InterfaceMethod state:()Lorg/apache/kafka/streams/processor/internals/Task$State;
       6: getstatic     #2                  // Field org/apache/kafka/streams/processor/internals/Task$State.CREATED:Lorg/apache/kafka/streams/processor/internals/Task$State;
       9: if_acmpeq     24
      12: aload_0
      13: invokeinterface #1,  1            // InterfaceMethod state:()Lorg/apache/kafka/streams/processor/internals/Task$State;
      18: getstatic     #3                  // Field org/apache/kafka/streams/processor/internals/Task$State.RESTORING:Lorg/apache/kafka/streams/processor/internals/Task$State;
      21: if_acmpne     28
      24: iconst_1
      25: goto          29
      28: iconst_0
      29: ireturn

  public abstract boolean isActive();

  public abstract boolean isClosed();

  public abstract void initializeIfNeeded();

  public abstract void completeRestoration();

  public abstract void addRecords(org.apache.kafka.common.TopicPartition, java.lang.Iterable<org.apache.kafka.clients.consumer.ConsumerRecord<byte[], byte[]>>);

  public abstract boolean commitNeeded();

  public abstract java.util.Map<org.apache.kafka.common.TopicPartition, org.apache.kafka.clients.consumer.OffsetAndMetadata> prepareCommit();

  public abstract void postCommit();

  public abstract void suspend();

  public abstract void resume();

  public abstract void closeClean();

  public abstract void closeDirty();

  public abstract void update(java.util.Set<org.apache.kafka.common.TopicPartition>, java.util.Map<java.lang.String, java.util.List<java.lang.String>>);

  public abstract void closeCleanAndRecycleState();

  public abstract void revive();

  public abstract org.apache.kafka.streams.processor.StateStore getStore(java.lang.String);

  public abstract java.util.Set<org.apache.kafka.common.TopicPartition> inputPartitions();

  public abstract java.util.Collection<org.apache.kafka.common.TopicPartition> changelogPartitions();

  public abstract java.util.Map<org.apache.kafka.common.TopicPartition, java.lang.Long> changelogOffsets();

  public abstract void markChangelogAsCorrupted(java.util.Collection<org.apache.kafka.common.TopicPartition>);

  public default java.util.Map<org.apache.kafka.common.TopicPartition, java.lang.Long> purgeableOffsets();
    Code:
       0: invokestatic  #4                  // Method java/util/Collections.emptyMap:()Ljava/util/Map;
       3: areturn

  public default void recordProcessBatchTime(long);
    Code:
       0: return

  public default void recordProcessTimeRatioAndBufferSize(long, long);
    Code:
       0: return

  public default boolean process(long);
    Code:
       0: iconst_0
       1: ireturn

  public default boolean commitRequested();
    Code:
       0: iconst_0
       1: ireturn

  public default boolean maybePunctuateStreamTime();
    Code:
       0: iconst_0
       1: ireturn

  public default boolean maybePunctuateSystemTime();
    Code:
       0: iconst_0
       1: ireturn
}
